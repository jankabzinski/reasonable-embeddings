{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229c6875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/janek/reasonable-embeddings\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4534b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.simplefact import *\n",
    "from src.simplefact.syntax import *\n",
    "from src.generate import *\n",
    "from src.reasoner import *\n",
    "from src.utils import *\n",
    "from src.vis import *\n",
    "\n",
    "seed = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dae809a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported class expression ('SubClassOf', 'pizza:American', ('ObjectHasValue', 'pizza:hasCountryOfOrigin', 'pizza:America'))\n",
      "Unsupported class expression ('SubClassOf', 'pizza:AmericanHot', ('ObjectHasValue', 'pizza:hasCountryOfOrigin', 'pizza:America'))\n",
      "Unsupported class expression ('EquivalentClasses', 'pizza:Country', ('ObjectIntersectionOf', 'pizza:DomainConcept', ('ObjectOneOf', 'pizza:America', 'pizza:England', 'pizza:France', 'pizza:Germany', 'pizza:Italy')))\n",
      "Unsupported class expression ('EquivalentClasses', 'pizza:InterestingPizza', ('ObjectIntersectionOf', 'pizza:Pizza', ('ObjectMinCardinality', '3', 'pizza:hasTopping')))\n",
      "Unsupported class expression ('SubClassOf', 'pizza:MozzarellaTopping', ('ObjectHasValue', 'pizza:hasCountryOfOrigin', 'pizza:Italy'))\n",
      "Unsupported class expression ('SubClassOf', 'pizza:Napoletana', ('ObjectHasValue', 'pizza:hasCountryOfOrigin', 'pizza:Italy'))\n",
      "Unsupported class expression ('EquivalentClasses', 'pizza:RealItalianPizza', ('ObjectIntersectionOf', 'pizza:Pizza', ('ObjectHasValue', 'pizza:hasCountryOfOrigin', 'pizza:Italy')))\n",
      "Unsupported class expression ('SubClassOf', 'pizza:Veneziana', ('ObjectHasValue', 'pizza:hasCountryOfOrigin', 'pizza:Italy'))\n",
      "Dropping unused role pizza:hasCountryOfOrigin\n",
      "Dropping unused role pizza:isBaseOf\n",
      "Dropping unused role pizza:isIngredientOf\n",
      "Dropping unused role pizza:isToppingOf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FaCT++.Kernel: Reasoner for the SROIQ(D) Description Logic, 64-bit\n",
      "Copyright (C) Dmitry Tsarkov, 2002-2017. Version 1.7.0-SNAPSHOT (01 January 2017)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Onto 99 concepts, 4 roles, 287 axioms>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto = load_ofn('local/out/dataset/pizza.ofn')\n",
    "onto.use_annotations_as_names()\n",
    "onto.use_prefix('pizza:')\n",
    "fact = Reasoner.from_onto(onto=onto, timeout=None)\n",
    "    \n",
    "C = onto.concept_by_name\n",
    "R = onto.role_by_name\n",
    "onto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2316780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10201\n",
      "0.09459856876776787\n"
     ]
    }
   ],
   "source": [
    "queries, answers, qset = [], [], set()\n",
    "concepts = list(range(onto.n_concepts)) + [TOP, BOT]\n",
    "\n",
    "for c in concepts:\n",
    "    for d in concepts:\n",
    "        append_unique((SUB, c, d), queries, qset)\n",
    "\n",
    "for query in queries:\n",
    "    answers.append(float(fact.check_axiom(query)))\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "queries, answers = jointshuffle(rng, queries, answers)\n",
    "\n",
    "print(len(answers))\n",
    "print(np.mean(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e665e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = [core(x) for x in queries]\n",
    "y_te = answers\n",
    "idx_te = [0]*len(X_te)\n",
    "data = idx_te, X_te, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a8a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_test = pd.DataFrame({\n",
    "    'ontology_id': data[0],\n",
    "    'X': data[1],\n",
    "    'y': data[2]\n",
    "})\n",
    "\n",
    "def stratified_group_split(data, group_col, stratify_col, test_size=0.2, val_size=0.2):\n",
    "    groups = data[group_col].unique()\n",
    "    train_idx, val_idx, test_idx = [], [], []\n",
    "\n",
    "    for group in groups:\n",
    "        group_data = data[data[group_col] == group]\n",
    "        train_data, temp_data = train_test_split(group_data, test_size=(test_size + val_size), stratify=group_data[stratify_col], random_state=seed)\n",
    "        val_data, test_data = train_test_split(temp_data, test_size=test_size/(test_size + val_size), stratify=temp_data[stratify_col], random_state=seed)\n",
    "\n",
    "        train_idx.extend(train_data.index)\n",
    "        val_idx.extend(val_data.index)\n",
    "        test_idx.extend(test_data.index)\n",
    "\n",
    "    return data.loc[train_idx], data.loc[val_idx], data.loc[test_idx]\n",
    "\n",
    "train_data, val_data, test_data = stratified_group_split(data_test, 'ontology_id', 'y', test_size=0.2, val_size=0.2)\n",
    "\n",
    "X_train = train_data['X'].tolist()\n",
    "y_train = train_data['y'].tolist()\n",
    "ontology_id_train = train_data['ontology_id'].tolist()\n",
    "\n",
    "data_tr = [ontology_id_train,X_train, y_train] \n",
    "\n",
    "X_val = val_data['X'].tolist()\n",
    "y_val = val_data['y'].tolist()\n",
    "ontology_id_val = val_data['ontology_id'].tolist()\n",
    "\n",
    "data_vl = [ontology_id_val, X_val, y_val] \n",
    "\n",
    "X_te = X_test = test_data['X'].tolist()\n",
    "y_te = y_test = test_data['y'].tolist()\n",
    "idx_te = ontology_id_test = test_data['ontology_id'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2379dfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head params 3293\n",
      "embs params 1430\n",
      "train epoch 00/23 | batch 193/192 | loss 0.8001 | val loss 0.8007 | acc 0.0946 | f1 0.1729 | prec 0.0946 | recall 1.0000 | roc auc 0.4431 | pr auc 0.0823 | elapsed 1.06s\n",
      "train epoch 01/23 | batch 193/192 | loss 0.4414 | val loss 0.2283 | acc 0.9206 | f1 0.3017 | prec 0.8974 | recall 0.1813 | roc auc 0.8393 | pr auc 0.4979 | elapsed 2.11s\n",
      "train epoch 02/23 | batch 193/192 | loss 0.1813 | val loss 0.1538 | acc 0.9593 | f1 0.7331 | prec 0.9661 | recall 0.5907 | roc auc 0.8987 | pr auc 0.7937 | elapsed 2.01s\n",
      "train epoch 03/23 | batch 193/192 | loss 0.1365 | val loss 0.1332 | acc 0.9613 | f1 0.7584 | prec 0.9254 | recall 0.6425 | roc auc 0.9159 | pr auc 0.8334 | elapsed 2.22s\n",
      "train epoch 04/23 | batch 193/192 | loss 0.1256 | val loss 0.1302 | acc 0.9613 | f1 0.7584 | prec 0.9254 | recall 0.6425 | roc auc 0.9200 | pr auc 0.8383 | elapsed 2.08s\n",
      "train epoch 05/23 | batch 193/192 | loss 0.1203 | val loss 0.1308 | acc 0.9613 | f1 0.7599 | prec 0.9191 | recall 0.6477 | roc auc 0.9210 | pr auc 0.8404 | elapsed 1.99s\n",
      "train epoch 06/23 | batch 193/192 | loss 0.1178 | val loss 0.1320 | acc 0.9613 | f1 0.7613 | prec 0.9130 | recall 0.6528 | roc auc 0.9219 | pr auc 0.8402 | elapsed 2.19s\n",
      "train epoch 07/23 | batch 193/192 | loss 0.1160 | val loss 0.1338 | acc 0.9608 | f1 0.7576 | prec 0.9124 | recall 0.6477 | roc auc 0.9217 | pr auc 0.8404 | elapsed 2.15s\n",
      "train epoch 08/23 | batch 193/192 | loss 0.1144 | val loss 0.1327 | acc 0.9613 | f1 0.7642 | prec 0.9014 | recall 0.6632 | roc auc 0.9232 | pr auc 0.8414 | elapsed 1.88s\n",
      "train epoch 09/23 | batch 193/192 | loss 0.1139 | val loss 0.1321 | acc 0.9657 | f1 0.7965 | prec 0.9073 | recall 0.7098 | roc auc 0.9240 | pr auc 0.8428 | elapsed 1.97s\n",
      "train epoch 10/23 | batch 193/192 | loss 0.1091 | val loss 0.1340 | acc 0.9637 | f1 0.7811 | prec 0.9103 | recall 0.6839 | roc auc 0.9240 | pr auc 0.8463 | elapsed 1.97s\n",
      "train epoch 11/23 | batch 193/192 | loss 0.1053 | val loss 0.1342 | acc 0.9627 | f1 0.7683 | prec 0.9333 | recall 0.6528 | roc auc 0.9242 | pr auc 0.8462 | elapsed 1.88s\n",
      "train epoch 12/23 | batch 193/192 | loss 0.1010 | val loss 0.1326 | acc 0.9637 | f1 0.7771 | prec 0.9281 | recall 0.6684 | roc auc 0.9266 | pr auc 0.8498 | elapsed 2.12s\n",
      "train epoch 13/23 | batch 193/192 | loss 0.0941 | val loss 0.1239 | acc 0.9706 | f1 0.8286 | prec 0.9236 | recall 0.7513 | roc auc 0.9314 | pr auc 0.8629 | elapsed 2.22s\n",
      "train epoch 14/23 | batch 193/192 | loss 0.0813 | val loss 0.1184 | acc 0.9716 | f1 0.8371 | prec 0.9141 | recall 0.7720 | roc auc 0.9368 | pr auc 0.8720 | elapsed 1.92s\n",
      "train epoch 15/23 | batch 193/192 | loss 0.0718 | val loss 0.1152 | acc 0.9730 | f1 0.8433 | prec 0.9367 | recall 0.7668 | roc auc 0.9412 | pr auc 0.8783 | elapsed 2.06s\n",
      "train epoch 16/23 | batch 193/192 | loss 0.0632 | val loss 0.1167 | acc 0.9725 | f1 0.8436 | prec 0.9152 | recall 0.7824 | roc auc 0.9416 | pr auc 0.8824 | elapsed 2.06s\n",
      "train epoch 17/23 | batch 193/192 | loss 0.0567 | val loss 0.1175 | acc 0.9696 | f1 0.8306 | prec 0.8786 | recall 0.7876 | roc auc 0.9443 | pr auc 0.8860 | elapsed 2.12s\n",
      "train epoch 18/23 | batch 193/192 | loss 0.0512 | val loss 0.1204 | acc 0.9711 | f1 0.8375 | prec 0.8941 | recall 0.7876 | roc auc 0.9459 | pr auc 0.8852 | elapsed 2.07s\n",
      "train epoch 19/23 | batch 193/192 | loss 0.0443 | val loss 0.1221 | acc 0.9721 | f1 0.8455 | prec 0.8864 | recall 0.8083 | roc auc 0.9491 | pr auc 0.8878 | elapsed 2.05s\n",
      "train epoch 20/23 | batch 193/192 | loss 0.0401 | val loss 0.1250 | acc 0.9711 | f1 0.8392 | prec 0.8851 | recall 0.7979 | roc auc 0.9500 | pr auc 0.8890 | elapsed 2.16s\n",
      "train epoch 21/23 | batch 193/192 | loss 0.0351 | val loss 0.1281 | acc 0.9725 | f1 0.8495 | prec 0.8827 | recall 0.8187 | roc auc 0.9521 | pr auc 0.8913 | elapsed 2.10s\n",
      "train epoch 22/23 | batch 193/192 | loss 0.0319 | val loss 0.1339 | acc 0.9716 | f1 0.8432 | prec 0.8814 | recall 0.8083 | roc auc 0.9521 | pr auc 0.8931 | elapsed 2.00s\n",
      "train epoch 23/23 | batch 193/192 | loss 0.0274 | val loss 0.1386 | acc 0.9711 | f1 0.8401 | prec 0.8807 | recall 0.8031 | roc auc 0.9531 | pr auc 0.8941 | elapsed 2.01s\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "T.manual_seed(seed)\n",
    "reasoner = NeuralReasoner(emb_size=10, hidden_size=16, onto=onto)\n",
    "print('head params', paramcount(reasoner.head))\n",
    "print('embs params', paramcount(reasoner.embs))\n",
    "\n",
    "log = train(data_tr, data_vl, reasoner.head, [reasoner.embs], freeze_reasoner=False,\n",
    "            epoch_count=23, batch_size=32, lr_reasoner=0.0015, lr_encoder=0.0015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "821cb2f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m     reasoner\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 3\u001b[0m     _, y_te, Y_te \u001b[38;5;241m=\u001b[39m \u001b[43meval_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreasoner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mreasoner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_te\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(report([onto], y_te, Y_te, idx_te))\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnfrozen reasoner head (trained on concept name subsumption)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/reasonable-embeddings/src/reasoner.py:172\u001b[0m, in \u001b[0;36meval_batch\u001b[0;34m(reasoner, encoders, X, y, onto_idx, indices, backward, detach)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)))\n\u001b[1;32m    171\u001b[0m emb \u001b[38;5;241m=\u001b[39m [encoders[onto_idx[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[0;32m--> 172\u001b[0m X_ \u001b[38;5;241m=\u001b[39m [core(X[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[1;32m    173\u001b[0m y_ \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mfloat\u001b[39m(y[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    174\u001b[0m Y_ \u001b[38;5;241m=\u001b[39m reasoner\u001b[38;5;241m.\u001b[39mclassify_batch(X_, emb)\n",
      "File \u001b[0;32m~/reasonable-embeddings/src/reasoner.py:172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X)))\n\u001b[1;32m    171\u001b[0m emb \u001b[38;5;241m=\u001b[39m [encoders[onto_idx[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[0;32m--> 172\u001b[0m X_ \u001b[38;5;241m=\u001b[39m [\u001b[43mcore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[1;32m    173\u001b[0m y_ \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mfloat\u001b[39m(y[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    174\u001b[0m Y_ \u001b[38;5;241m=\u001b[39m reasoner\u001b[38;5;241m.\u001b[39mclassify_batch(X_, emb)\n",
      "File \u001b[0;32m~/reasonable-embeddings/src/reasoner.py:14\u001b[0m, in \u001b[0;36mcore\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcore\u001b[39m(expr):\n\u001b[0;32m---> 14\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(expr, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m expr \u001b[38;5;241m==\u001b[39m TOP \u001b[38;5;129;01mor\u001b[39;00m expr \u001b[38;5;241m==\u001b[39m BOT:\n\u001b[1;32m     15\u001b[0m \t\t\u001b[38;5;28;01mreturn\u001b[39;00m expr\n\u001b[1;32m     16\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m expr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m NOT:\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "with T.no_grad():\n",
    "    reasoner.eval()\n",
    "    _, y_test, Y_te = eval_batch(reasoner.head, [reasoner.embs], X_te, y_te, idx_te)\n",
    "\n",
    "print(report([onto], y_test, Y_te, idx_te))\n",
    "plt.suptitle('Unfrozen reasoner head (trained on concept name subsumption)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2748bb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rekord  Prawdziwa Etykieta     Predykcja  Feature_0  Feature_1  Feature_2\n",
      "0        2                 1.0  6.042001e-01          0         77         41\n",
      "1        4                 1.0  6.294634e-10          0          7          7\n",
      "2       13                 0.0  3.592578e-01          0         70         59\n",
      "3       18                 1.0  5.098262e-01          0         98         96\n",
      "4       48                 0.0  9.717807e-01          0         23         18\n",
      "..     ...                 ...           ...        ...        ...        ...\n",
      "69    1882                 1.0  6.454030e-01          0         31         79\n",
      "70    1912                 0.0  3.863693e-01          0         96         64\n",
      "71    1932                 0.0  7.041200e-01          0         87         92\n",
      "72    1985                 1.0  1.409085e-01          0         27         97\n",
      "73    1993                 1.0  6.880909e-08          0         35         35\n",
      "\n",
      "[74 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Upewnij się, że Y_te i y_te są numpy array\n",
    "Y_te = np.array(Y_te)\n",
    "y_te = np.array(y_te)\n",
    "X_te = np.array(X_te)\n",
    "\n",
    "# Oblicz błędne predykcje\n",
    "błędne_predykcje = abs(Y_te - y_te) > 0.3\n",
    "\n",
    "# Wyodrębnij rekordy, na których model popełnił błąd\n",
    "rekordy_z_błędem = X_te[błędne_predykcje, :]\n",
    "\n",
    "# Połącz rekordy z ich prawdziwymi etykietami i predykcjami\n",
    "wyniki = pd.DataFrame({\n",
    "    'Rekord': np.arange(len(X_te))[błędne_predykcje],\n",
    "    'Prawdziwa Etykieta': y_te[błędne_predykcje],\n",
    "    'Predykcja': Y_te[błędne_predykcje],\n",
    "})\n",
    "\n",
    "content_df = pd.DataFrame(rekordy_z_błędem, columns=[f'Feature_{i}' for i in range(X_te.shape[1])])\n",
    "wyniki = pd.concat([wyniki.reset_index(drop=True), content_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(wyniki)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
