{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18bfe2a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T12:17:07.124764Z",
     "start_time": "2022-04-30T12:17:07.101705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/janek/reasonable-embeddings\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8067b382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T12:17:09.033517Z",
     "start_time": "2022-04-30T12:17:07.143374Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from src.reasoner_mod import *\n",
    "from src.generate import load_dataset, prepare_data, count_elements, reduce_dataset, make_dataset\n",
    "from src.reasoner import *\n",
    "from src.utils import *\n",
    "from src.vis import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dde9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2022\n",
    "dataset_path = 'local/out/dataset/sub-100.json'\n",
    "ts = timestr()\n",
    "train_onto, test_onto, data_tr, data_vl, data_te = load_dataset(dataset_path)\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97058569",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr, data_vl, data_te_tr, data_te_vl, idx_te_te, X_te_te, y_te_te = prepare_data(data_tr, data_vl, data_te, seed, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, onto in enumerate(train_onto):\n",
    "    fact = Reasoner.from_onto(onto, timeout=None)\n",
    "    queries, answers = make_dataset(onto, fact, rng, 400 - data_vl[0].count(i), 7 , 9)\n",
    "    data_vl[1].extend(queries)\n",
    "    data_vl[0].extend(len(queries)*[i])\n",
    "    data_vl[2].extend(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c24f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr = reduce_dataset(data_tr, len(train_onto), 1600, data_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595ee525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.188546875\n",
      "0.191374246405936\n",
      "\n",
      "0.2203348305430788\n",
      "0.18243243243243243\n",
      "0.18631643249847282\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(data_tr[2]))\n",
    "print(np.mean(data_vl[2]))\n",
    "print()\n",
    "print(np.mean(data_te_tr[2]))\n",
    "print(np.mean(data_te_vl[2]))\n",
    "print(np.mean(y_te_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c90bdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T12:38:41.791580Z",
     "start_time": "2022-04-30T12:38:41.759078Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created reasoner with 3283 parameters\n",
      "created 40 encoders with 1270 parameters each\n"
     ]
    }
   ],
   "source": [
    "emb_size = 10\n",
    "hidden_size = 16\n",
    "epoch_count = 10\n",
    "test_epoch_count = 10\n",
    "batch_size = 32\n",
    "\n",
    "T.manual_seed(seed)\n",
    "trained_reasoner = ModifiedReasonerHead(emb_size=emb_size, hidden_size=hidden_size)\n",
    "encoders = [ModifiedEmbeddingLayer.from_onto(onto, emb_size=emb_size) for onto in train_onto]\n",
    "\n",
    "print(f'created reasoner with {paramcount(trained_reasoner)} parameters')\n",
    "print(f'created {len(encoders)} encoders with {paramcount(encoders[0])} parameters each')\n",
    "# train_logger = train_mod(data_tr, data_vl, trained_reasoner, encoders, epoch_count=epoch_count,\n",
    "                        #   batch_size=batch_size, identities_weight=0.02, identitity_weight_decay=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0de569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 19:38:21,402] A new study created in memory with name: no-name-0368d66f-0d76-424c-a79c-d272e41ed5f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/10 | batch 2001/2000 | loss 0.8458 | val loss 0.6940 | acc 0.5032 | f1 0.2387 | prec 0.1689 | recall 0.4071 | roc auc 0.4492 | pr auc 0.1681 | elapsed 36.51s\n",
      "train epoch 01/10 | batch 2001/2000 | loss 0.6651 | val loss 0.4598 | acc 0.8397 | f1 0.3128 | prec 0.8708 | recall 0.1906 | roc auc 0.6908 | pr auc 0.4937 | elapsed 108.06s\n",
      "train epoch 02/10 | batch 2001/2000 | loss 0.4498 | val loss 0.3689 | acc 0.8513 | f1 0.5233 | prec 0.6769 | recall 0.4265 | roc auc 0.8183 | pr auc 0.6260 | elapsed 118.30s\n",
      "train epoch 03/10 | batch 2001/2000 | loss 0.3241 | val loss 0.3292 | acc 0.8754 | f1 0.6310 | prec 0.7283 | recall 0.5565 | roc auc 0.8585 | pr auc 0.7142 | elapsed 98.95s\n",
      "train epoch 04/10 | batch 2001/2000 | loss 0.2450 | val loss 0.3047 | acc 0.8856 | f1 0.6769 | prec 0.7367 | recall 0.6260 | roc auc 0.8820 | pr auc 0.7681 | elapsed 93.74s\n",
      "train epoch 05/10 | batch 2001/2000 | loss 0.1949 | val loss 0.2875 | acc 0.8953 | f1 0.7128 | prec 0.7507 | recall 0.6785 | roc auc 0.8987 | pr auc 0.8018 | elapsed 86.03s\n",
      "train epoch 06/10 | batch 2001/2000 | loss 0.1640 | val loss 0.2791 | acc 0.8966 | f1 0.7250 | prec 0.7381 | recall 0.7124 | roc auc 0.9104 | pr auc 0.8234 | elapsed 87.56s\n",
      "train epoch 07/10 | batch 2001/2000 | loss 0.1434 | val loss 0.2815 | acc 0.8980 | f1 0.7375 | prec 0.7265 | recall 0.7488 | roc auc 0.9188 | pr auc 0.8370 | elapsed 88.00s\n",
      "train epoch 08/10 | batch 2001/2000 | loss 0.1283 | val loss 0.2666 | acc 0.9028 | f1 0.7493 | prec 0.7396 | recall 0.7593 | roc auc 0.9252 | pr auc 0.8518 | elapsed 89.04s\n",
      "train epoch 09/10 | batch 2001/2000 | loss 0.1166 | val loss 0.2619 | acc 0.9065 | f1 0.7608 | prec 0.7452 | recall 0.7771 | roc auc 0.9295 | pr auc 0.8607 | elapsed 88.10s\n",
      "train epoch 10/10 | batch 2000/2000 | loss 0.1075 | elapsed 88.51s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-07-29 19:54:47,886] Trial 0 failed with parameters: {'identity_weight': 11, 'decay': 914} because of the following error: TypeError('cannot unpack non-iterable TrainingLogger object').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/janek/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_6247/587486989.py\", line 14, in objective\n",
      "    y, Y = train_mod(data_tr, data_vl, trained_reasoner, encoders, epoch_count=10,\n",
      "TypeError: cannot unpack non-iterable TrainingLogger object\n",
      "[W 2024-07-29 19:54:47,888] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 10/10 | batch 2001/2000 | loss 0.1075 | val loss 0.2673 | acc 0.9065 | f1 0.7636 | prec 0.7396 | recall 0.7892 | roc auc 0.9332 | pr auc 0.8663 | elapsed 90.02s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable TrainingLogger object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(rec, prec)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m roc_auc_score(y,Y)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m \u001b[38;5;241m+\u001b[39m accuracy_score(y,K)\n\u001b[1;32m     26\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Wyświetl najlepsze hiperparametry oraz wartość dokładności\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNajlepsze hiperparametry:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     12\u001b[0m id_weight\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     13\u001b[0m decay\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m---> 14\u001b[0m y, Y \u001b[38;5;241m=\u001b[39m train_mod(data_tr, data_vl, trained_reasoner, encoders, epoch_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     15\u001b[0m                         batch_size\u001b[38;5;241m=\u001b[39mbatch_size, identities_weight\u001b[38;5;241m=\u001b[39mid_weight, identitity_weight_decay\u001b[38;5;241m=\u001b[39mdecay)\n\u001b[1;32m     17\u001b[0m prec, rec, _ \u001b[38;5;241m=\u001b[39m precision_recall_curve(y, Y)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprc: \u001b[39m\u001b[38;5;124m'\u001b[39m, auc(rec, prec))\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable TrainingLogger object"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def objective(trial):\n",
    "    T.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    trained_reasoner = ModifiedReasonerHead(emb_size=emb_size, hidden_size=hidden_size)\n",
    "    encoders = [ModifiedEmbeddingLayer.from_onto(onto, emb_size=emb_size) for onto in train_onto]\n",
    "\n",
    "    id_weight = trial.suggest_int('identity_weight', 10, 100)\n",
    "    decay= trial.suggest_int('decay',900, 999)\n",
    "\n",
    "    id_weight/=1000\n",
    "    decay/=1000\n",
    "    y, Y = train_mod(data_tr, data_vl, trained_reasoner, encoders, epoch_count=15,\n",
    "                            batch_size=batch_size, identities_weight=id_weight, identitity_weight_decay=decay)\n",
    "    \n",
    "    prec, rec, _ = precision_recall_curve(y, Y)\n",
    "    \n",
    "    print('prc: ', auc(rec, prec))\n",
    "    print('roc: ', roc_auc_score(y,Y))\n",
    "    K = np.array(Y) > 0.5\n",
    "    print('acc: ',accuracy_score(y,K))\n",
    "\n",
    "    return auc(rec, prec)*10 + roc_auc_score(y,Y)*6 + accuracy_score(y,K)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Wyświetl najlepsze hiperparametry oraz wartość dokładności\n",
    "print('Najlepsze hiperparametry:')\n",
    "print(study.best_params)\n",
    "print('Wartość średniej dokładności dla najlepszych hiperparametrów:')\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7aa831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T12:39:07.917372Z",
     "start_time": "2022-04-30T12:39:07.917335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained reasoner\n",
      "train epoch 00/10 | batch 849/848 | loss 0.7694 | val loss 0.7728 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.4990 | pr auc 0.2375 | elapsed 7.20s\n",
      "train epoch 01/10 | batch 849/848 | loss 0.7689 | val loss 0.7724 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5104 | pr auc 0.2452 | elapsed 12.84s\n",
      "train epoch 02/10 | batch 849/848 | loss 0.7677 | val loss 0.7720 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5223 | pr auc 0.2537 | elapsed 12.80s\n",
      "train epoch 03/10 | batch 849/848 | loss 0.7664 | val loss 0.7715 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5342 | pr auc 0.2620 | elapsed 12.35s\n",
      "train epoch 04/10 | batch 849/848 | loss 0.7651 | val loss 0.7711 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5454 | pr auc 0.2704 | elapsed 12.64s\n",
      "train epoch 05/10 | batch 849/848 | loss 0.7638 | val loss 0.7706 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5556 | pr auc 0.2780 | elapsed 13.00s\n",
      "train epoch 06/10 | batch 849/848 | loss 0.7625 | val loss 0.7702 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5644 | pr auc 0.2849 | elapsed 13.07s\n",
      "train epoch 07/10 | batch 849/848 | loss 0.7612 | val loss 0.7698 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5722 | pr auc 0.2908 | elapsed 12.61s\n",
      "train epoch 08/10 | batch 849/848 | loss 0.7599 | val loss 0.7693 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5788 | pr auc 0.2960 | elapsed 12.91s\n",
      "train epoch 09/10 | batch 849/848 | loss 0.7586 | val loss 0.7689 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5845 | pr auc 0.3009 | elapsed 12.34s\n",
      "train epoch 10/10 | batch 849/848 | loss 0.7572 | val loss 0.7685 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5892 | pr auc 0.3049 | elapsed 12.81s\n"
     ]
    }
   ],
   "source": [
    "## --- TESTING\n",
    "trained_test_encoders = {}\n",
    "T.manual_seed(seed)\n",
    "test_logger = TrainingLogger(validate=True, metrics=batch_stats)\n",
    "\n",
    "for reasoner_name, reasoner in [('trained reasoner', trained_reasoner)]:\n",
    "    print(reasoner_name)\n",
    "    T.manual_seed(seed)\n",
    "    trained_test_encoders[reasoner_name] = test_encoders = [EmbeddingLayer.from_onto(onto, emb_size=emb_size) for onto in test_onto]\n",
    "    train_mod(data_te_tr, data_te_vl, reasoner, test_encoders, epoch_count=test_epoch_count, batch_size=batch_size, run_name=reasoner_name, freeze_reasoner=True, logger=test_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with T.no_grad():\n",
    "    # idx_te, X_te, y_te = data_te\n",
    "    _, _, Y_te_good = eval_batch(trained_reasoner, trained_test_encoders['trained reasoner'], X_te_te, y_te_te, idx_te_te)\n",
    "    # _, _, Y_te_rand = eval_batch(random_reasoner, trained_test_encoders['random reasoner'], X_te, y_te, idx_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb2c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T12:20:39.824396Z",
     "start_time": "2022-04-30T12:20:39.824337Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local/out/exp/20240716T183807\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(base)\n\u001b[1;32m      5\u001b[0m T\u001b[38;5;241m.\u001b[39msave(trained_reasoner\u001b[38;5;241m.\u001b[39mstate_dict(), base\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/reasoner.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m df_tr \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtrain_logger\u001b[49m\u001b[38;5;241m.\u001b[39mhistory_tr)\n\u001b[1;32m      7\u001b[0m df_vl \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(train_logger\u001b[38;5;241m.\u001b[39mhistory_vl)\n\u001b[1;32m      8\u001b[0m df_tr\u001b[38;5;241m.\u001b[39mto_csv(base\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_logger' is not defined"
     ]
    }
   ],
   "source": [
    "base = 'local/out/exp/' + ts\n",
    "mkdirp(base)\n",
    "print(base)\n",
    "\n",
    "T.save(trained_reasoner.state_dict(), base+'/reasoner.pt')\n",
    "df_tr = pd.DataFrame(train_logger.history_tr)\n",
    "df_vl = pd.DataFrame(train_logger.history_vl)\n",
    "df_tr.to_csv(base+'/train.csv', index=False)\n",
    "df_vl.to_csv(base+'/valid.csv', index=False)\n",
    "plot_train_history(df_tr, df_vl, save=base+'/train.png')\n",
    "\n",
    "test_history_by_onto = pd.DataFrame(test_logger.history_vl_by_onto)\n",
    "test_history = pd.DataFrame(test_logger.history_vl)\n",
    "test_results = pd.DataFrame(dict(idx_te=idx_te_te, y_te=y_te_te, Y_te_good=Y_te_good))\n",
    "test_history.to_csv(base+'/test.csv', index=False)\n",
    "test_history_by_onto.to_csv(base+'/test-grouped.csv', index=False)\n",
    "test_results.to_csv(base+'/test-results.csv', index=False)\n",
    "plot_test_history(test_history, test_history_by_onto)\n",
    "print(report(test_onto, y_te_te, np.array(Y_te_good), idx_te_te))\n",
    "# print(report(test_onto, y_te, np.array(Y_te_rand), idx_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec65fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e5a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0853,  0.0049,  0.0044,  0.1040, -0.2791, -0.0971, -0.0545, -0.2373,\n",
      "         0.0291, -0.1781], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0283, -0.1301,  0.1543, -0.1816,  0.1470, -0.1504, -0.1508, -0.1428,\n",
      "         0.1558,  0.1439], grad_fn=<AddBackward0>)\n",
      "0.14532663188874723\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input = encoder.concepts[ int(np.round( random.random() * encoder.n_concepts , 0) - 1) ]\n",
    "    losses.append( F.l1_loss(input, trained_reasoner.and_nn(im(input, input))).item() )\n",
    "\n",
    "\n",
    "print(input)\n",
    "print(trained_reasoner.and_nn(im( input, input)))\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8487,  0.3154, -0.0030, -0.4652,  0.9116, -0.0422,  0.2849,  0.1790,\n",
      "        -0.4642, -0.3235], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.5006,  0.4196, -0.2333, -0.1082,  0.1215,  0.4181,  0.3491,  0.4251,\n",
      "        -0.4716, -0.1767], grad_fn=<AddBackward0>)\n",
      "0.27251186221838\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input = encoder.concepts[ int(np.round( random.random() * encoder.n_concepts , 0) - 1) ]\n",
    "    losses.append(F.l1_loss(trained_reasoner.and_nn(im(trained_reasoner.bot_concept[0], input)), trained_reasoner.bot_concept[0]).item())\n",
    "print(trained_reasoner.bot_concept[0])\n",
    "print(trained_reasoner.and_nn(im(trained_reasoner.bot_concept[0], input)))\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0393, -0.1274, -0.2614, -0.1177, -0.0585, -0.0664,  0.1144, -0.2802,\n",
      "         0.1001,  0.0221], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.2182, -0.3193,  0.2273, -0.1661,  0.1478, -0.1756, -0.1602, -0.2823,\n",
      "         0.2452,  0.2916], grad_fn=<AddBackward0>)\n",
      "0.1793355718255043\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input = encoder.concepts[ int(np.round( random.random() * encoder.n_concepts , 0) - 1) ]\n",
    "    losses.append(F.l1_loss(trained_reasoner.and_nn(im(trained_reasoner.top_concept[0], input)), input).item())\n",
    "\n",
    "print(input)\n",
    "print(trained_reasoner.and_nn(im(trained_reasoner.top_concept[0], input)))\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5653f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8487,  0.3154, -0.0030, -0.4652,  0.9116, -0.0422,  0.2849,  0.1790,\n",
      "        -0.4642, -0.3235], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0291, -0.0860,  0.1372, -0.2300,  0.1739, -0.1169, -0.1536, -0.1260,\n",
      "         0.1137,  0.0972], grad_fn=<AddBackward0>)\n",
      "0.36536308377981186\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input = encoder.concepts[ int(np.round( random.random() * encoder.n_concepts , 0) - 1) ]\n",
    "    output = trained_reasoner.and_nn(im(trained_reasoner.not_nn(input), input))\n",
    "    losses.append(F.l1_loss(trained_reasoner.bot_concept[0], output).item())\n",
    "\n",
    "print(trained_reasoner.bot_concept[0])\n",
    "print(output)\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f65ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8487,  0.3154, -0.0030, -0.4652,  0.9116, -0.0422,  0.2849,  0.1790,\n",
      "        -0.4642, -0.3235], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.8487,  0.3152, -0.0028, -0.4649,  0.9116, -0.0422,  0.2849,  0.1790,\n",
      "        -0.4640, -0.3235], grad_fn=<SqueezeBackward3>)\n",
      "tensor(9.1464e-05, grad_fn=<L1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(trained_reasoner.bot_concept[0])\n",
    "output = trained_reasoner.not_nn(trained_reasoner.top_concept[0])\n",
    "print(output)\n",
    "print(F.l1_loss(trained_reasoner.bot_concept[0], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d1cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0286, -0.2194,  0.0205,  0.4425,  0.1463,  0.3542,  1.5009,  0.0721,\n",
      "        -0.2669,  0.2835], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0288, -0.2195,  0.0202,  0.4425,  0.1462,  0.3544,  1.5013,  0.0722,\n",
      "        -0.2671,  0.2835], grad_fn=<SqueezeBackward3>)\n",
      "tensor(0.0001, grad_fn=<L1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(trained_reasoner.top_concept[0])\n",
    "output = trained_reasoner.not_nn(trained_reasoner.bot_concept[0])\n",
    "print(output)\n",
    "print(F.l1_loss(trained_reasoner.top_concept[0], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79985d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1326, -0.0631,  0.0128, -0.1697,  0.1839,  0.0128, -0.0778, -0.0954,\n",
      "        -0.0058,  0.0982], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0459,  0.0285,  0.0899, -0.2081,  0.1915, -0.0053, -0.0852, -0.0492,\n",
      "        -0.0394,  0.0515], grad_fn=<AddBackward0>)\n",
      "0.03770795250311494\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input1 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "\n",
    "    input2 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "\n",
    "    input3 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "\n",
    "    losses.append(F.l1_loss(trained_reasoner.and_nn(im(input1, trained_reasoner.and_nn(im(input2, input3)))), trained_reasoner.and_nn(im(trained_reasoner.and_nn(im(input1, input2)), input3))).item())\n",
    "\n",
    "print(trained_reasoner.and_nn(im(input1, trained_reasoner.and_nn(im(input2, input3)))))\n",
    "print(trained_reasoner.and_nn(im(trained_reasoner.and_nn(im(input1, input2)), input3)))\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8878736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0574,  0.0155,  0.0813, -0.1991,  0.1782,  0.0296, -0.0436,  0.0211,\n",
      "        -0.0320,  0.0349], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1004, -0.0202,  0.0521, -0.2140,  0.1707, -0.0263, -0.0697,  0.0596,\n",
      "        -0.1071,  0.0224], grad_fn=<AddBackward0>)\n",
      "0.029833172308281065\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input1 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "    input2 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "\n",
    "    losses.append( F.l1_loss(trained_reasoner.and_nn(im(input1, input2)), trained_reasoner.and_nn(im(input2, input1))).item())\n",
    "\n",
    "print(trained_reasoner.and_nn(im(input1, input2)))\n",
    "print(trained_reasoner.and_nn(im(input2, input1)))\n",
    "\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e840d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1733,  0.2138, -0.0319, -0.2493,  0.1992,  0.0884,  0.0452,  0.0611,\n",
      "        -0.2770,  0.0685], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0836,  0.1108,  0.0115, -0.2417,  0.0640,  0.0104,  0.0819,  0.1758,\n",
      "        -0.1955, -0.0690], grad_fn=<AddBackward0>)\n",
      "0.1997889805585146\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input1 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "    losses.append(F.l1_loss(input1, trained_reasoner.and_nn(im(input1, trained_reasoner.top_concept[0]))).item())\n",
    "\n",
    "print(input1)\n",
    "print(trained_reasoner.and_nn(im(input1, trained_reasoner.top_concept[0])))\n",
    "\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58620be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999014347791672\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input1 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "    losses.append( T.sigmoid(trained_reasoner.sub_nn(im(input1, trained_reasoner.top_concept[0]))).item())\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b1bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input1 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "    losses.append(T.sigmoid(trained_reasoner.sub_nn(im(trained_reasoner.bot_concept[0], trained_reasoner.bot_concept[0]))).item())\n",
    "print(np.mean(losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
