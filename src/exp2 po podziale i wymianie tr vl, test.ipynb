{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18bfe2a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T12:17:07.124764Z",
     "start_time": "2022-04-30T12:17:07.101705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/janek/reasonable-embeddings\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8067b382",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T12:17:09.033517Z",
     "start_time": "2022-04-30T12:17:07.143374Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from src.reasoner_mod import *\n",
    "from src.generate import load_dataset, prepare_data, count_elements, reduce_dataset, make_dataset\n",
    "from src.reasoner import *\n",
    "from src.utils import *\n",
    "from src.vis import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dde9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2022\n",
    "dataset_path = 'local/out/dataset/sub-100.json'\n",
    "ts = timestr()\n",
    "train_onto, test_onto, data_tr, data_vl, data_te = load_dataset(dataset_path)\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97058569",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr, data_vl, data_te_tr, data_te_vl, idx_te_te, X_te_te, y_te_te = prepare_data(data_tr, data_vl, data_te, seed, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3389865d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FaCT++.Kernel: Reasoner for the SROIQ(D) Description Logic, 64-bit\n",
      "Copyright (C) Dmitry Tsarkov, 2002-2017. Version 1.7.0-SNAPSHOT (01 January 2017)\n"
     ]
    }
   ],
   "source": [
    "for i, onto in enumerate(train_onto):\n",
    "    fact = Reasoner.from_onto(onto, timeout=None)\n",
    "    queries, answers = make_dataset(onto, fact, rng, 400 - data_vl[0].count(i), 6 , 9)\n",
    "    data_vl[1].extend(queries)\n",
    "    data_vl[0].extend(len(queries)*[i])\n",
    "    data_vl[2].extend(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c24f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr = reduce_dataset(data_tr, len(train_onto), 1600, data_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595ee525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19665625\n",
      "0.1984375\n",
      "\n",
      "0.2203348305430788\n",
      "0.18243243243243243\n",
      "0.18631643249847282\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(data_tr[2]))\n",
    "print(np.mean(data_vl[2]))\n",
    "print()\n",
    "print(np.mean(data_te_tr[2]))\n",
    "print(np.mean(data_te_vl[2]))\n",
    "print(np.mean(y_te_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69c90bdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T12:38:41.791580Z",
     "start_time": "2022-04-30T12:38:41.759078Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created reasoner with 3283 parameters\n",
      "created 40 encoders with 1270 parameters each\n"
     ]
    }
   ],
   "source": [
    "emb_size = 10\n",
    "hidden_size = 16\n",
    "epoch_count = 10\n",
    "test_epoch_count = 10\n",
    "batch_size = 32\n",
    "\n",
    "T.manual_seed(seed)\n",
    "trained_reasoner = ModifiedReasonerHead(emb_size=emb_size, hidden_size=hidden_size)\n",
    "encoders = [ModifiedEmbeddingLayer.from_onto(onto, emb_size=emb_size) for onto in train_onto]\n",
    "\n",
    "print(f'created reasoner with {paramcount(trained_reasoner)} parameters')\n",
    "print(f'created {len(encoders)} encoders with {paramcount(encoders[0])} parameters each')\n",
    "# train_logger = train_mod(data_tr, data_vl, trained_reasoner, encoders, epoch_count=epoch_count,\n",
    "                        #   batch_size=batch_size, identities_weight=0.02, identitity_weight_decay=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0de569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 21:50:52,988] A new study created in memory with name: no-name-883fadcc-5f90-4742-8e3c-3ef21fc99c24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 1.2986 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 27.21s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.9129 | val loss 0.4752 | acc 0.8279 | f1 0.3493 | prec 0.6998 | recall 0.2328 | roc auc 0.6655 | pr auc 0.4696 | elapsed 84.20s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5503 | val loss 0.4013 | acc 0.8436 | f1 0.5136 | prec 0.6709 | recall 0.4161 | roc auc 0.7757 | pr auc 0.6049 | elapsed 90.90s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3791 | val loss 0.3795 | acc 0.8581 | f1 0.6008 | prec 0.6802 | recall 0.5380 | roc auc 0.8182 | pr auc 0.6808 | elapsed 90.42s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2598 | val loss 0.3593 | acc 0.8699 | f1 0.6508 | prec 0.6961 | recall 0.6110 | roc auc 0.8467 | pr auc 0.7326 | elapsed 90.20s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1995 | val loss 0.3371 | acc 0.8784 | f1 0.6807 | prec 0.7105 | recall 0.6532 | roc auc 0.8677 | pr auc 0.7711 | elapsed 90.42s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1691 | val loss 0.3232 | acc 0.8832 | f1 0.7010 | prec 0.7123 | recall 0.6901 | roc auc 0.8833 | pr auc 0.7976 | elapsed 96.64s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1476 | val loss 0.3082 | acc 0.8909 | f1 0.7217 | prec 0.7309 | recall 0.7128 | roc auc 0.8957 | pr auc 0.8183 | elapsed 88.38s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1316 | val loss 0.3008 | acc 0.8934 | f1 0.7329 | prec 0.7291 | recall 0.7367 | roc auc 0.9058 | pr auc 0.8333 | elapsed 88.77s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1196 | val loss 0.2928 | acc 0.8978 | f1 0.7450 | prec 0.7378 | recall 0.7524 | roc auc 0.9133 | pr auc 0.8450 | elapsed 87.93s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1103 | val loss 0.2866 | acc 0.9017 | f1 0.7540 | prec 0.7488 | recall 0.7594 | roc auc 0.9192 | pr auc 0.8542 | elapsed 86.29s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1029 | val loss 0.2859 | acc 0.9009 | f1 0.7542 | prec 0.7424 | recall 0.7663 | roc auc 0.9238 | pr auc 0.8610 | elapsed 87.36s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0967 | val loss 0.2857 | acc 0.9024 | f1 0.7584 | prec 0.7452 | recall 0.7720 | roc auc 0.9269 | pr auc 0.8658 | elapsed 89.22s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0912 | val loss 0.2845 | acc 0.9052 | f1 0.7642 | prec 0.7545 | recall 0.7742 | roc auc 0.9293 | pr auc 0.8699 | elapsed 88.61s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0864 | val loss 0.2891 | acc 0.9056 | f1 0.7665 | prec 0.7524 | recall 0.7811 | roc auc 0.9311 | pr auc 0.8723 | elapsed 88.50s\n",
      "train epoch 15/15 | batch 2000/2000 | loss 0.0820 | elapsed 86.20s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 22:13:39,811] Trial 0 finished with value: 15.237173928131474 and parameters: {'identity_weight': 36, 'decay': 959}. Best is trial 0 with value: 15.237173928131474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 15/15 | batch 2001/2000 | loss 0.0820 | val loss 0.2982 | acc 0.9043 | f1 0.7661 | prec 0.7439 | recall 0.7896 | roc auc 0.9324 | pr auc 0.8739 | elapsed 88.69s\n",
      "prc:  0.8738663923872139\n",
      "roc:  0.9323662507098893\n",
      "acc:  0.9043125\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.9233 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 31.10s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 1.2448 | val loss 0.4777 | acc 0.8234 | f1 0.3712 | prec 0.6328 | recall 0.2627 | roc auc 0.6686 | pr auc 0.4714 | elapsed 88.88s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.6995 | val loss 0.4065 | acc 0.8401 | f1 0.5185 | prec 0.6439 | recall 0.4340 | roc auc 0.7736 | pr auc 0.6029 | elapsed 89.19s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.4614 | val loss 0.3842 | acc 0.8546 | f1 0.6040 | prec 0.6569 | recall 0.5591 | roc auc 0.8173 | pr auc 0.6810 | elapsed 88.55s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2852 | val loss 0.3639 | acc 0.8644 | f1 0.6453 | prec 0.6707 | recall 0.6217 | roc auc 0.8467 | pr auc 0.7338 | elapsed 88.64s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2054 | val loss 0.3418 | acc 0.8732 | f1 0.6735 | prec 0.6885 | recall 0.6592 | roc auc 0.8678 | pr auc 0.7725 | elapsed 90.94s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1712 | val loss 0.3314 | acc 0.8802 | f1 0.7001 | prec 0.6955 | recall 0.7049 | roc auc 0.8830 | pr auc 0.7980 | elapsed 88.73s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1484 | val loss 0.3176 | acc 0.8862 | f1 0.7174 | prec 0.7075 | recall 0.7276 | roc auc 0.8947 | pr auc 0.8173 | elapsed 89.32s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1321 | val loss 0.3107 | acc 0.8883 | f1 0.7258 | prec 0.7077 | recall 0.7449 | roc auc 0.9042 | pr auc 0.8315 | elapsed 89.95s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1199 | val loss 0.3027 | acc 0.8931 | f1 0.7373 | prec 0.7193 | recall 0.7562 | roc auc 0.9112 | pr auc 0.8423 | elapsed 87.96s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1103 | val loss 0.2965 | acc 0.8990 | f1 0.7505 | prec 0.7360 | recall 0.7657 | roc auc 0.9168 | pr auc 0.8511 | elapsed 88.56s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1025 | val loss 0.2967 | acc 0.8981 | f1 0.7505 | prec 0.7300 | recall 0.7723 | roc auc 0.9214 | pr auc 0.8576 | elapsed 89.48s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0959 | val loss 0.2966 | acc 0.8991 | f1 0.7533 | prec 0.7313 | recall 0.7767 | roc auc 0.9243 | pr auc 0.8620 | elapsed 90.50s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0900 | val loss 0.2954 | acc 0.9026 | f1 0.7608 | prec 0.7418 | recall 0.7808 | roc auc 0.9267 | pr auc 0.8660 | elapsed 89.90s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0848 | val loss 0.3004 | acc 0.9031 | f1 0.7636 | prec 0.7403 | recall 0.7883 | roc auc 0.9285 | pr auc 0.8684 | elapsed 90.54s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0801 | val loss 0.3108 | acc 0.9006 | f1 0.7609 | prec 0.7276 | recall 0.7975 | roc auc 0.9299 | pr auc 0.8699 | elapsed 90.25s\n",
      "prc:  0.8699195454747578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 22:36:35,320] Trial 1 finished with value: 15.179041723223886 and parameters: {'identity_weight': 79, 'decay': 909}. Best is trial 0 with value: 15.237173928131474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc:  0.9298806280793848\n",
      "acc:  0.9005625\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.4294 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 31.41s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.9755 | val loss 0.4764 | acc 0.8273 | f1 0.3557 | prec 0.6843 | recall 0.2403 | roc auc 0.6660 | pr auc 0.4697 | elapsed 88.35s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5742 | val loss 0.4021 | acc 0.8433 | f1 0.5155 | prec 0.6667 | recall 0.4202 | roc auc 0.7756 | pr auc 0.6052 | elapsed 90.49s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3880 | val loss 0.3801 | acc 0.8579 | f1 0.6023 | prec 0.6776 | recall 0.5420 | roc auc 0.8183 | pr auc 0.6813 | elapsed 87.28s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2589 | val loss 0.3592 | acc 0.8691 | f1 0.6496 | prec 0.6930 | recall 0.6113 | roc auc 0.8469 | pr auc 0.7333 | elapsed 89.97s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1984 | val loss 0.3369 | acc 0.8780 | f1 0.6796 | prec 0.7096 | recall 0.6520 | roc auc 0.8678 | pr auc 0.7717 | elapsed 89.17s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1677 | val loss 0.3233 | acc 0.8826 | f1 0.7000 | prec 0.7102 | recall 0.6901 | roc auc 0.8833 | pr auc 0.7978 | elapsed 95.29s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1461 | val loss 0.3084 | acc 0.8906 | f1 0.7215 | prec 0.7288 | recall 0.7143 | roc auc 0.8956 | pr auc 0.8183 | elapsed 87.62s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1299 | val loss 0.3010 | acc 0.8938 | f1 0.7340 | prec 0.7294 | recall 0.7386 | roc auc 0.9056 | pr auc 0.8333 | elapsed 98.13s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1178 | val loss 0.2929 | acc 0.8981 | f1 0.7459 | prec 0.7384 | recall 0.7537 | roc auc 0.9130 | pr auc 0.8448 | elapsed 92.24s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1084 | val loss 0.2866 | acc 0.9019 | f1 0.7541 | prec 0.7501 | recall 0.7581 | roc auc 0.9188 | pr auc 0.8541 | elapsed 90.65s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1009 | val loss 0.2856 | acc 0.9021 | f1 0.7565 | prec 0.7472 | recall 0.7660 | roc auc 0.9235 | pr auc 0.8609 | elapsed 81.06s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0946 | val loss 0.2853 | acc 0.9031 | f1 0.7595 | prec 0.7484 | recall 0.7710 | roc auc 0.9265 | pr auc 0.8656 | elapsed 84.71s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0891 | val loss 0.2839 | acc 0.9068 | f1 0.7674 | prec 0.7604 | recall 0.7745 | roc auc 0.9289 | pr auc 0.8698 | elapsed 82.37s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0843 | val loss 0.2879 | acc 0.9077 | f1 0.7703 | prec 0.7607 | recall 0.7802 | roc auc 0.9308 | pr auc 0.8724 | elapsed 79.73s\n",
      "train epoch 15/15 | batch 2000/2000 | loss 0.0799 | elapsed 76.93s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 22:59:06,355] Trial 2 finished with value: 15.23796909768126 and parameters: {'identity_weight': 45, 'decay': 922}. Best is trial 2 with value: 15.23796909768126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 15/15 | batch 2001/2000 | loss 0.0799 | val loss 0.2965 | acc 0.9058 | f1 0.7690 | prec 0.7491 | recall 0.7899 | roc auc 0.9321 | pr auc 0.8739 | elapsed 79.46s\n",
      "prc:  0.8739340278668505\n",
      "roc:  0.9321360531687924\n",
      "acc:  0.9058125\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.1098 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 31.44s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.8006 | val loss 0.4771 | acc 0.8291 | f1 0.3344 | prec 0.7355 | recall 0.2164 | roc auc 0.6594 | pr auc 0.4644 | elapsed 88.01s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4969 | val loss 0.4008 | acc 0.8438 | f1 0.5023 | prec 0.6831 | recall 0.3972 | roc auc 0.7742 | pr auc 0.6017 | elapsed 90.66s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3535 | val loss 0.3765 | acc 0.8601 | f1 0.5972 | prec 0.6968 | recall 0.5225 | roc auc 0.8167 | pr auc 0.6786 | elapsed 88.84s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2601 | val loss 0.3552 | acc 0.8726 | f1 0.6503 | prec 0.7139 | recall 0.5972 | roc auc 0.8458 | pr auc 0.7318 | elapsed 88.80s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1972 | val loss 0.3353 | acc 0.8797 | f1 0.6812 | prec 0.7182 | recall 0.6479 | roc auc 0.8673 | pr auc 0.7693 | elapsed 88.81s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1661 | val loss 0.3193 | acc 0.8865 | f1 0.7055 | prec 0.7272 | recall 0.6850 | roc auc 0.8835 | pr auc 0.7971 | elapsed 89.74s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1450 | val loss 0.3030 | acc 0.8949 | f1 0.7284 | prec 0.7474 | recall 0.7102 | roc auc 0.8965 | pr auc 0.8191 | elapsed 89.80s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1290 | val loss 0.2943 | acc 0.8971 | f1 0.7384 | prec 0.7449 | recall 0.7320 | roc auc 0.9069 | pr auc 0.8351 | elapsed 89.12s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1168 | val loss 0.2856 | acc 0.9019 | f1 0.7520 | prec 0.7544 | recall 0.7496 | roc auc 0.9148 | pr auc 0.8477 | elapsed 89.78s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1074 | val loss 0.2798 | acc 0.9054 | f1 0.7607 | prec 0.7640 | recall 0.7575 | roc auc 0.9209 | pr auc 0.8575 | elapsed 92.19s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0998 | val loss 0.2786 | acc 0.9056 | f1 0.7630 | prec 0.7600 | recall 0.7660 | roc auc 0.9257 | pr auc 0.8646 | elapsed 90.23s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0935 | val loss 0.2785 | acc 0.9071 | f1 0.7676 | prec 0.7623 | recall 0.7729 | roc auc 0.9287 | pr auc 0.8696 | elapsed 89.47s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0880 | val loss 0.2769 | acc 0.9103 | f1 0.7746 | prec 0.7721 | recall 0.7770 | roc auc 0.9310 | pr auc 0.8738 | elapsed 90.00s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0832 | val loss 0.2809 | acc 0.9101 | f1 0.7755 | prec 0.7690 | recall 0.7820 | roc auc 0.9328 | pr auc 0.8764 | elapsed 88.73s\n",
      "train epoch 15/15 | batch 2000/2000 | loss 0.0789 | elapsed 85.66s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 23:22:03,622] Trial 3 finished with value: 15.293134819419421 and parameters: {'identity_weight': 23, 'decay': 952}. Best is trial 3 with value: 15.293134819419421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 15/15 | batch 2001/2000 | loss 0.0789 | val loss 0.2885 | acc 0.9097 | f1 0.7764 | prec 0.7632 | recall 0.7899 | roc auc 0.9340 | pr auc 0.8779 | elapsed 88.49s\n",
      "prc:  0.8779258600903972\n",
      "roc:  0.9340314530859081\n",
      "acc:  0.9096875\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.5311 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.00s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 1.0297 | val loss 0.4758 | acc 0.8265 | f1 0.3604 | prec 0.6712 | recall 0.2463 | roc auc 0.6676 | pr auc 0.4709 | elapsed 86.92s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5980 | val loss 0.4028 | acc 0.8432 | f1 0.5181 | prec 0.6639 | recall 0.4249 | roc auc 0.7755 | pr auc 0.6052 | elapsed 88.94s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.4018 | val loss 0.3807 | acc 0.8571 | f1 0.6031 | prec 0.6720 | recall 0.5471 | roc auc 0.8183 | pr auc 0.6816 | elapsed 87.54s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2629 | val loss 0.3599 | acc 0.8685 | f1 0.6493 | prec 0.6896 | recall 0.6135 | roc auc 0.8470 | pr auc 0.7337 | elapsed 89.94s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1996 | val loss 0.3376 | acc 0.8770 | f1 0.6785 | prec 0.7048 | recall 0.6542 | roc auc 0.8679 | pr auc 0.7719 | elapsed 89.84s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1683 | val loss 0.3246 | acc 0.8820 | f1 0.6996 | prec 0.7070 | recall 0.6923 | roc auc 0.8832 | pr auc 0.7978 | elapsed 90.50s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1464 | val loss 0.3100 | acc 0.8902 | f1 0.7216 | prec 0.7261 | recall 0.7172 | roc auc 0.8954 | pr auc 0.8180 | elapsed 89.23s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1302 | val loss 0.3031 | acc 0.8932 | f1 0.7343 | prec 0.7255 | recall 0.7433 | roc auc 0.9053 | pr auc 0.8328 | elapsed 90.15s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1181 | val loss 0.2948 | acc 0.8975 | f1 0.7449 | prec 0.7358 | recall 0.7543 | roc auc 0.9126 | pr auc 0.8442 | elapsed 88.06s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1087 | val loss 0.2886 | acc 0.9025 | f1 0.7562 | prec 0.7505 | recall 0.7619 | roc auc 0.9183 | pr auc 0.8533 | elapsed 90.08s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1012 | val loss 0.2879 | acc 0.9020 | f1 0.7563 | prec 0.7465 | recall 0.7663 | roc auc 0.9229 | pr auc 0.8600 | elapsed 88.65s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0948 | val loss 0.2877 | acc 0.9032 | f1 0.7603 | prec 0.7474 | recall 0.7735 | roc auc 0.9259 | pr auc 0.8647 | elapsed 89.49s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0893 | val loss 0.2865 | acc 0.9062 | f1 0.7669 | prec 0.7564 | recall 0.7776 | roc auc 0.9283 | pr auc 0.8688 | elapsed 90.08s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0844 | val loss 0.2905 | acc 0.9069 | f1 0.7693 | prec 0.7566 | recall 0.7824 | roc auc 0.9302 | pr auc 0.8713 | elapsed 88.47s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0800 | val loss 0.2995 | acc 0.9044 | f1 0.7666 | prec 0.7438 | recall 0.7909 | roc auc 0.9315 | pr auc 0.8729 | elapsed 107.79s\n",
      "prc:  0.8728653645693004\n",
      "roc:  0.9315065248422895\n",
      "acc:  0.9044375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-29 23:45:14,450] Trial 4 finished with value: 15.22213029474674 and parameters: {'identity_weight': 52, 'decay': 916}. Best is trial 3 with value: 15.293134819419421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 1.4149 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 39.34s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.9848 | val loss 0.4761 | acc 0.8269 | f1 0.3562 | prec 0.6803 | recall 0.2413 | roc auc 0.6665 | pr auc 0.4700 | elapsed 101.94s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5867 | val loss 0.4024 | acc 0.8436 | f1 0.5181 | prec 0.6668 | recall 0.4236 | roc auc 0.7757 | pr auc 0.6054 | elapsed 97.81s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3972 | val loss 0.3813 | acc 0.8572 | f1 0.6031 | prec 0.6723 | recall 0.5468 | roc auc 0.8185 | pr auc 0.6811 | elapsed 99.80s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2608 | val loss 0.3595 | acc 0.8681 | f1 0.6489 | prec 0.6878 | recall 0.6142 | roc auc 0.8472 | pr auc 0.7341 | elapsed 98.94s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2020 | val loss 0.3377 | acc 0.8769 | f1 0.6785 | prec 0.7040 | recall 0.6548 | roc auc 0.8681 | pr auc 0.7722 | elapsed 100.29s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1710 | val loss 0.3248 | acc 0.8822 | f1 0.7005 | prec 0.7072 | recall 0.6939 | roc auc 0.8835 | pr auc 0.7982 | elapsed 99.37s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1493 | val loss 0.3105 | acc 0.8900 | f1 0.7219 | prec 0.7244 | recall 0.7194 | roc auc 0.8956 | pr auc 0.8182 | elapsed 99.98s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1334 | val loss 0.3036 | acc 0.8921 | f1 0.7321 | prec 0.7218 | recall 0.7427 | roc auc 0.9054 | pr auc 0.8328 | elapsed 102.90s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1215 | val loss 0.2955 | acc 0.8968 | f1 0.7439 | prec 0.7329 | recall 0.7553 | roc auc 0.9127 | pr auc 0.8441 | elapsed 104.72s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1124 | val loss 0.2896 | acc 0.9004 | f1 0.7519 | prec 0.7437 | recall 0.7603 | roc auc 0.9184 | pr auc 0.8530 | elapsed 107.71s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1050 | val loss 0.2895 | acc 0.9004 | f1 0.7540 | prec 0.7397 | recall 0.7688 | roc auc 0.9230 | pr auc 0.8595 | elapsed 111.48s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0989 | val loss 0.2897 | acc 0.9008 | f1 0.7558 | prec 0.7384 | recall 0.7742 | roc auc 0.9259 | pr auc 0.8640 | elapsed 103.15s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0934 | val loss 0.2889 | acc 0.9033 | f1 0.7608 | prec 0.7473 | recall 0.7748 | roc auc 0.9282 | pr auc 0.8679 | elapsed 103.27s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0885 | val loss 0.2942 | acc 0.9040 | f1 0.7636 | prec 0.7466 | recall 0.7814 | roc auc 0.9300 | pr auc 0.8702 | elapsed 97.01s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0841 | val loss 0.3046 | acc 0.9009 | f1 0.7608 | prec 0.7304 | recall 0.7937 | roc auc 0.9313 | pr auc 0.8716 | elapsed 100.10s\n",
      "prc:  0.8716122512688838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 00:11:25,857] Trial 5 finished with value: 15.204593539419049 and parameters: {'identity_weight': 44, 'decay': 967}. Best is trial 3 with value: 15.293134819419421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc:  0.9312555877883685\n",
      "acc:  0.9009375\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.6473 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 34.99s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 1.1124 | val loss 0.4762 | acc 0.8257 | f1 0.3657 | prec 0.6579 | recall 0.2532 | roc auc 0.6685 | pr auc 0.4715 | elapsed 99.79s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.6455 | val loss 0.4043 | acc 0.8424 | f1 0.5203 | prec 0.6572 | recall 0.4306 | roc auc 0.7751 | pr auc 0.6047 | elapsed 100.21s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.4345 | val loss 0.3826 | acc 0.8549 | f1 0.6017 | prec 0.6610 | recall 0.5521 | roc auc 0.8182 | pr auc 0.6815 | elapsed 100.09s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2742 | val loss 0.3615 | acc 0.8661 | f1 0.6470 | prec 0.6782 | recall 0.6186 | roc auc 0.8474 | pr auc 0.7344 | elapsed 101.76s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2049 | val loss 0.3398 | acc 0.8742 | f1 0.6750 | prec 0.6929 | recall 0.6580 | roc auc 0.8682 | pr auc 0.7728 | elapsed 100.73s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1723 | val loss 0.3286 | acc 0.8801 | f1 0.6985 | prec 0.6969 | recall 0.7002 | roc auc 0.8835 | pr auc 0.7983 | elapsed 101.14s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1500 | val loss 0.3150 | acc 0.8864 | f1 0.7166 | prec 0.7098 | recall 0.7235 | roc auc 0.8953 | pr auc 0.8178 | elapsed 99.95s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1340 | val loss 0.3082 | acc 0.8889 | f1 0.7269 | prec 0.7098 | recall 0.7449 | roc auc 0.9049 | pr auc 0.8320 | elapsed 93.81s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1222 | val loss 0.3005 | acc 0.8934 | f1 0.7376 | prec 0.7208 | recall 0.7553 | roc auc 0.9119 | pr auc 0.8429 | elapsed 93.48s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1128 | val loss 0.2946 | acc 0.8988 | f1 0.7494 | prec 0.7364 | recall 0.7628 | roc auc 0.9174 | pr auc 0.8516 | elapsed 93.97s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1053 | val loss 0.2951 | acc 0.8981 | f1 0.7502 | prec 0.7302 | recall 0.7713 | roc auc 0.9219 | pr auc 0.8580 | elapsed 94.71s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0989 | val loss 0.2954 | acc 0.8983 | f1 0.7514 | prec 0.7297 | recall 0.7745 | roc auc 0.9248 | pr auc 0.8624 | elapsed 91.86s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0932 | val loss 0.2947 | acc 0.9021 | f1 0.7600 | prec 0.7402 | recall 0.7808 | roc auc 0.9271 | pr auc 0.8662 | elapsed 95.65s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0882 | val loss 0.3003 | acc 0.9021 | f1 0.7614 | prec 0.7370 | recall 0.7874 | roc auc 0.9289 | pr auc 0.8685 | elapsed 97.79s\n",
      "train epoch 15/15 | batch 2000/2000 | loss 0.0836 | elapsed 95.10s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 00:36:27,192] Trial 6 finished with value: 15.177847452562665 and parameters: {'identity_weight': 60, 'decay': 949}. Best is trial 3 with value: 15.293134819419421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 15/15 | batch 2001/2000 | loss 0.0836 | val loss 0.3115 | acc 0.8992 | f1 0.7584 | prec 0.7231 | recall 0.7972 | roc auc 0.9301 | pr auc 0.8698 | elapsed 98.12s\n",
      "prc:  0.8697865772887755\n",
      "roc:  0.9301323632791514\n",
      "acc:  0.8991875\n",
      "train epoch 00/15 | batch 2001/2000 | loss 2.0686 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 34.74s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 1.3843 | val loss 0.4800 | acc 0.8207 | f1 0.3729 | prec 0.6093 | recall 0.2687 | roc auc 0.6679 | pr auc 0.4704 | elapsed 96.37s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.7946 | val loss 0.4099 | acc 0.8384 | f1 0.5212 | prec 0.6326 | recall 0.4431 | roc auc 0.7720 | pr auc 0.6002 | elapsed 97.43s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.5283 | val loss 0.3884 | acc 0.8502 | f1 0.5983 | prec 0.6393 | recall 0.5622 | roc auc 0.8166 | pr auc 0.6795 | elapsed 104.60s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.3101 | val loss 0.3695 | acc 0.8612 | f1 0.6445 | prec 0.6553 | recall 0.6340 | roc auc 0.8466 | pr auc 0.7336 | elapsed 108.21s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2172 | val loss 0.3496 | acc 0.8702 | f1 0.6740 | prec 0.6721 | recall 0.6759 | roc auc 0.8676 | pr auc 0.7724 | elapsed 98.38s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1818 | val loss 0.3416 | acc 0.8729 | f1 0.6904 | prec 0.6683 | recall 0.7140 | roc auc 0.8823 | pr auc 0.7969 | elapsed 94.90s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1597 | val loss 0.3280 | acc 0.8804 | f1 0.7078 | prec 0.6868 | recall 0.7301 | roc auc 0.8934 | pr auc 0.8151 | elapsed 93.67s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1438 | val loss 0.3231 | acc 0.8836 | f1 0.7190 | prec 0.6898 | recall 0.7509 | roc auc 0.9025 | pr auc 0.8286 | elapsed 95.03s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1317 | val loss 0.3168 | acc 0.8871 | f1 0.7275 | prec 0.6982 | recall 0.7594 | roc auc 0.9092 | pr auc 0.8387 | elapsed 92.55s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1220 | val loss 0.3115 | acc 0.8905 | f1 0.7341 | prec 0.7083 | recall 0.7619 | roc auc 0.9146 | pr auc 0.8468 | elapsed 92.44s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1141 | val loss 0.3149 | acc 0.8894 | f1 0.7352 | prec 0.7002 | recall 0.7739 | roc auc 0.9189 | pr auc 0.8525 | elapsed 93.21s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.1074 | val loss 0.3163 | acc 0.8902 | f1 0.7382 | prec 0.7005 | recall 0.7802 | roc auc 0.9215 | pr auc 0.8562 | elapsed 92.20s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.1012 | val loss 0.3171 | acc 0.8934 | f1 0.7450 | prec 0.7094 | recall 0.7843 | roc auc 0.9237 | pr auc 0.8595 | elapsed 93.24s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0955 | val loss 0.3269 | acc 0.8928 | f1 0.7451 | prec 0.7051 | recall 0.7899 | roc auc 0.9252 | pr auc 0.8610 | elapsed 92.04s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0904 | val loss 0.3426 | acc 0.8896 | f1 0.7426 | prec 0.6912 | recall 0.8022 | roc auc 0.9262 | pr auc 0.8618 | elapsed 91.76s\n",
      "prc:  0.8618224123243821\n",
      "roc:  0.9262131601970807\n",
      "acc:  0.889625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 01:01:01,281] Trial 7 finished with value: 15.065128084426304 and parameters: {'identity_weight': 89, 'decay': 983}. Best is trial 3 with value: 15.293134819419421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 1.4730 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.67s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 1.0270 | val loss 0.4758 | acc 0.8264 | f1 0.3596 | prec 0.6707 | recall 0.2457 | roc auc 0.6676 | pr auc 0.4708 | elapsed 89.49s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.6111 | val loss 0.4031 | acc 0.8429 | f1 0.5187 | prec 0.6618 | recall 0.4265 | roc auc 0.7757 | pr auc 0.6053 | elapsed 92.07s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.4143 | val loss 0.3821 | acc 0.8559 | f1 0.6027 | prec 0.6657 | recall 0.5506 | roc auc 0.8185 | pr auc 0.6813 | elapsed 91.64s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2668 | val loss 0.3606 | acc 0.8668 | f1 0.6470 | prec 0.6824 | recall 0.6151 | roc auc 0.8474 | pr auc 0.7344 | elapsed 91.72s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2052 | val loss 0.3389 | acc 0.8759 | f1 0.6781 | prec 0.6985 | recall 0.6589 | roc auc 0.8683 | pr auc 0.7725 | elapsed 91.89s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1736 | val loss 0.3271 | acc 0.8807 | f1 0.6988 | prec 0.7001 | recall 0.6976 | roc auc 0.8836 | pr auc 0.7982 | elapsed 92.38s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1518 | val loss 0.3135 | acc 0.8883 | f1 0.7198 | prec 0.7167 | recall 0.7228 | roc auc 0.8954 | pr auc 0.8179 | elapsed 90.77s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1360 | val loss 0.3068 | acc 0.8894 | f1 0.7275 | prec 0.7120 | recall 0.7436 | roc auc 0.9050 | pr auc 0.8321 | elapsed 91.51s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1245 | val loss 0.2993 | acc 0.8948 | f1 0.7406 | prec 0.7248 | recall 0.7572 | roc auc 0.9121 | pr auc 0.8431 | elapsed 95.36s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1154 | val loss 0.2937 | acc 0.8981 | f1 0.7474 | prec 0.7352 | recall 0.7600 | roc auc 0.9177 | pr auc 0.8517 | elapsed 91.52s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1081 | val loss 0.2945 | acc 0.8977 | f1 0.7492 | prec 0.7294 | recall 0.7701 | roc auc 0.9221 | pr auc 0.8580 | elapsed 92.98s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.1021 | val loss 0.2951 | acc 0.8982 | f1 0.7511 | prec 0.7294 | recall 0.7742 | roc auc 0.9250 | pr auc 0.8623 | elapsed 94.01s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0966 | val loss 0.2949 | acc 0.9015 | f1 0.7582 | prec 0.7392 | recall 0.7783 | roc auc 0.9272 | pr auc 0.8659 | elapsed 91.44s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0916 | val loss 0.3013 | acc 0.9009 | f1 0.7584 | prec 0.7348 | recall 0.7836 | roc auc 0.9290 | pr auc 0.8681 | elapsed 91.86s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0873 | val loss 0.3135 | acc 0.8968 | f1 0.7534 | prec 0.7160 | recall 0.7950 | roc auc 0.9301 | pr auc 0.8692 | elapsed 91.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 01:24:37,728] Trial 8 finished with value: 15.16935182967373 and parameters: {'identity_weight': 48, 'decay': 986}. Best is trial 3 with value: 15.293134819419421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prc:  0.869199765782679\n",
      "roc:  0.9301006953078232\n",
      "acc:  0.89675\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.9669 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 33.29s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 1.2837 | val loss 0.4783 | acc 0.8231 | f1 0.3724 | prec 0.6287 | recall 0.2646 | roc auc 0.6685 | pr auc 0.4712 | elapsed 91.40s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.7248 | val loss 0.4075 | acc 0.8393 | f1 0.5182 | prec 0.6394 | recall 0.4356 | roc auc 0.7731 | pr auc 0.6021 | elapsed 93.53s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.4785 | val loss 0.3853 | acc 0.8529 | f1 0.6014 | prec 0.6503 | recall 0.5594 | roc auc 0.8171 | pr auc 0.6807 | elapsed 92.41s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2920 | val loss 0.3653 | acc 0.8629 | f1 0.6441 | prec 0.6644 | recall 0.6249 | roc auc 0.8467 | pr auc 0.7338 | elapsed 90.74s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2083 | val loss 0.3437 | acc 0.8728 | f1 0.6738 | prec 0.6857 | recall 0.6624 | roc auc 0.8677 | pr auc 0.7726 | elapsed 92.57s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1735 | val loss 0.3343 | acc 0.8789 | f1 0.6996 | prec 0.6891 | recall 0.7106 | roc auc 0.8828 | pr auc 0.7978 | elapsed 92.22s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1508 | val loss 0.3202 | acc 0.8853 | f1 0.7161 | prec 0.7038 | recall 0.7288 | roc auc 0.8943 | pr auc 0.8167 | elapsed 91.36s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1347 | val loss 0.3138 | acc 0.8871 | f1 0.7240 | prec 0.7032 | recall 0.7461 | roc auc 0.9037 | pr auc 0.8307 | elapsed 91.82s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1225 | val loss 0.3062 | acc 0.8919 | f1 0.7357 | prec 0.7148 | recall 0.7578 | roc auc 0.9107 | pr auc 0.8413 | elapsed 92.22s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1128 | val loss 0.3002 | acc 0.8962 | f1 0.7448 | prec 0.7271 | recall 0.7635 | roc auc 0.9162 | pr auc 0.8499 | elapsed 91.41s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1049 | val loss 0.3011 | acc 0.8959 | f1 0.7464 | prec 0.7222 | recall 0.7723 | roc auc 0.9207 | pr auc 0.8562 | elapsed 93.27s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0982 | val loss 0.3012 | acc 0.8969 | f1 0.7493 | prec 0.7238 | recall 0.7767 | roc auc 0.9235 | pr auc 0.8605 | elapsed 92.97s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0922 | val loss 0.3004 | acc 0.8999 | f1 0.7561 | prec 0.7322 | recall 0.7817 | roc auc 0.9259 | pr auc 0.8643 | elapsed 92.73s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0868 | val loss 0.3065 | acc 0.8999 | f1 0.7575 | prec 0.7292 | recall 0.7880 | roc auc 0.9277 | pr auc 0.8666 | elapsed 92.59s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0820 | val loss 0.3180 | acc 0.8978 | f1 0.7563 | prec 0.7179 | recall 0.7991 | roc auc 0.9290 | pr auc 0.8679 | elapsed 91.74s\n",
      "prc:  0.8679131505351287\n",
      "roc:  0.9289642215775659\n",
      "acc:  0.8978125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 01:48:17,216] Trial 9 finished with value: 15.150729334816685 and parameters: {'identity_weight': 82, 'decay': 929}. Best is trial 3 with value: 15.293134819419421.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 0.9355 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 31.92s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.6965 | val loss 0.4817 | acc 0.8306 | f1 0.3008 | prec 0.8317 | recall 0.1836 | roc auc 0.6458 | pr auc 0.4508 | elapsed 91.91s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4520 | val loss 0.4032 | acc 0.8437 | f1 0.4844 | prec 0.7011 | recall 0.3701 | roc auc 0.7692 | pr auc 0.5914 | elapsed 91.93s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3310 | val loss 0.3774 | acc 0.8606 | f1 0.5858 | prec 0.7139 | recall 0.4967 | roc auc 0.8111 | pr auc 0.6698 | elapsed 90.78s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2563 | val loss 0.3509 | acc 0.8748 | f1 0.6439 | prec 0.7392 | recall 0.5704 | roc auc 0.8407 | pr auc 0.7272 | elapsed 92.89s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2076 | val loss 0.3311 | acc 0.8836 | f1 0.6807 | prec 0.7466 | recall 0.6255 | roc auc 0.8632 | pr auc 0.7654 | elapsed 92.16s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1735 | val loss 0.3160 | acc 0.8906 | f1 0.7084 | prec 0.7520 | recall 0.6696 | roc auc 0.8813 | pr auc 0.7937 | elapsed 92.06s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1470 | val loss 0.3014 | acc 0.8974 | f1 0.7310 | prec 0.7621 | recall 0.7024 | roc auc 0.8965 | pr auc 0.8177 | elapsed 92.81s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1273 | val loss 0.2899 | acc 0.9016 | f1 0.7463 | prec 0.7637 | recall 0.7298 | roc auc 0.9078 | pr auc 0.8353 | elapsed 92.65s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1147 | val loss 0.2800 | acc 0.9069 | f1 0.7606 | prec 0.7768 | recall 0.7452 | roc auc 0.9160 | pr auc 0.8492 | elapsed 93.54s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1051 | val loss 0.2745 | acc 0.9114 | f1 0.7719 | prec 0.7895 | recall 0.7550 | roc auc 0.9221 | pr auc 0.8599 | elapsed 92.98s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0974 | val loss 0.2727 | acc 0.9121 | f1 0.7759 | prec 0.7854 | recall 0.7666 | roc auc 0.9270 | pr auc 0.8675 | elapsed 92.85s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0911 | val loss 0.2729 | acc 0.9136 | f1 0.7804 | prec 0.7874 | recall 0.7735 | roc auc 0.9301 | pr auc 0.8729 | elapsed 92.56s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0858 | val loss 0.2722 | acc 0.9174 | f1 0.7883 | prec 0.8017 | recall 0.7754 | roc auc 0.9322 | pr auc 0.8773 | elapsed 91.87s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0811 | val loss 0.2760 | acc 0.9181 | f1 0.7916 | prec 0.7997 | recall 0.7836 | roc auc 0.9339 | pr auc 0.8802 | elapsed 93.39s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0769 | val loss 0.2823 | acc 0.9178 | f1 0.7928 | prec 0.7934 | recall 0.7921 | roc auc 0.9352 | pr auc 0.8820 | elapsed 93.74s\n",
      "prc:  0.8820242015339889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 02:12:00,396] Trial 10 finished with value: 15.349425072967554 and parameters: {'identity_weight': 11, 'decay': 943}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc:  0.9352284262712776\n",
      "acc:  0.9178125\n",
      "train epoch 00/15 | batch 2001/2000 | loss 0.9645 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 33.56s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7133 | val loss 0.4799 | acc 0.8308 | f1 0.3093 | prec 0.8145 | recall 0.1909 | roc auc 0.6498 | pr auc 0.4550 | elapsed 90.84s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4585 | val loss 0.4024 | acc 0.8442 | f1 0.4892 | prec 0.6999 | recall 0.3761 | roc auc 0.7706 | pr auc 0.5941 | elapsed 92.49s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3344 | val loss 0.3767 | acc 0.8604 | f1 0.5876 | prec 0.7103 | recall 0.5011 | roc auc 0.8126 | pr auc 0.6722 | elapsed 92.13s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2575 | val loss 0.3508 | acc 0.8748 | f1 0.6462 | prec 0.7352 | recall 0.5764 | roc auc 0.8423 | pr auc 0.7291 | elapsed 91.85s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2065 | val loss 0.3318 | acc 0.8828 | f1 0.6808 | prec 0.7403 | recall 0.6302 | roc auc 0.8648 | pr auc 0.7669 | elapsed 91.09s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1702 | val loss 0.3185 | acc 0.8882 | f1 0.7056 | prec 0.7392 | recall 0.6750 | roc auc 0.8827 | pr auc 0.7948 | elapsed 92.25s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1437 | val loss 0.3010 | acc 0.8966 | f1 0.7296 | prec 0.7580 | recall 0.7033 | roc auc 0.8968 | pr auc 0.8184 | elapsed 91.97s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1272 | val loss 0.2901 | acc 0.9015 | f1 0.7459 | prec 0.7641 | recall 0.7285 | roc auc 0.9078 | pr auc 0.8356 | elapsed 91.39s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1148 | val loss 0.2807 | acc 0.9061 | f1 0.7592 | prec 0.7727 | recall 0.7461 | roc auc 0.9159 | pr auc 0.8492 | elapsed 91.51s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1053 | val loss 0.2752 | acc 0.9101 | f1 0.7692 | prec 0.7837 | recall 0.7553 | roc auc 0.9221 | pr auc 0.8597 | elapsed 90.94s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0977 | val loss 0.2735 | acc 0.9110 | f1 0.7740 | prec 0.7802 | recall 0.7679 | roc auc 0.9269 | pr auc 0.8672 | elapsed 92.58s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0914 | val loss 0.2736 | acc 0.9131 | f1 0.7796 | prec 0.7844 | recall 0.7748 | roc auc 0.9300 | pr auc 0.8725 | elapsed 91.63s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0860 | val loss 0.2727 | acc 0.9164 | f1 0.7867 | prec 0.7972 | recall 0.7764 | roc auc 0.9321 | pr auc 0.8770 | elapsed 90.87s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0813 | val loss 0.2766 | acc 0.9169 | f1 0.7890 | prec 0.7955 | recall 0.7827 | roc auc 0.9339 | pr auc 0.8798 | elapsed 91.93s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0771 | val loss 0.2831 | acc 0.9166 | f1 0.7904 | prec 0.7886 | recall 0.7921 | roc auc 0.9352 | pr auc 0.8816 | elapsed 90.22s\n",
      "prc:  0.8816069132740579\n",
      "roc:  0.9351567036576569\n",
      "acc:  0.916625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 02:35:30,892] Trial 11 finished with value: 15.343634354686522 and parameters: {'identity_weight': 13, 'decay': 942}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 0.9500 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.07s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7047 | val loss 0.4808 | acc 0.8308 | f1 0.3057 | prec 0.8232 | recall 0.1877 | roc auc 0.6479 | pr auc 0.4529 | elapsed 89.63s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4549 | val loss 0.4028 | acc 0.8438 | f1 0.4858 | prec 0.7001 | recall 0.3720 | roc auc 0.7699 | pr auc 0.5927 | elapsed 91.49s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3325 | val loss 0.3771 | acc 0.8606 | f1 0.5867 | prec 0.7127 | recall 0.4986 | roc auc 0.8118 | pr auc 0.6710 | elapsed 92.03s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2567 | val loss 0.3508 | acc 0.8749 | f1 0.6454 | prec 0.7374 | recall 0.5739 | roc auc 0.8415 | pr auc 0.7281 | elapsed 89.88s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2070 | val loss 0.3313 | acc 0.8831 | f1 0.6807 | prec 0.7434 | recall 0.6277 | roc auc 0.8640 | pr auc 0.7662 | elapsed 91.36s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1720 | val loss 0.3170 | acc 0.8895 | f1 0.7073 | prec 0.7455 | recall 0.6728 | roc auc 0.8820 | pr auc 0.7943 | elapsed 90.88s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1449 | val loss 0.3016 | acc 0.8967 | f1 0.7297 | prec 0.7588 | recall 0.7027 | roc auc 0.8967 | pr auc 0.8179 | elapsed 89.29s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1271 | val loss 0.2900 | acc 0.9016 | f1 0.7464 | prec 0.7641 | recall 0.7294 | roc auc 0.9078 | pr auc 0.8354 | elapsed 90.64s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1147 | val loss 0.2803 | acc 0.9065 | f1 0.7600 | prec 0.7744 | recall 0.7461 | roc auc 0.9159 | pr auc 0.8491 | elapsed 90.67s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1051 | val loss 0.2749 | acc 0.9106 | f1 0.7699 | prec 0.7865 | recall 0.7540 | roc auc 0.9221 | pr auc 0.8597 | elapsed 91.37s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0975 | val loss 0.2731 | acc 0.9115 | f1 0.7748 | prec 0.7825 | recall 0.7672 | roc auc 0.9269 | pr auc 0.8673 | elapsed 91.98s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0911 | val loss 0.2733 | acc 0.9133 | f1 0.7799 | prec 0.7858 | recall 0.7742 | roc auc 0.9300 | pr auc 0.8726 | elapsed 91.51s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0858 | val loss 0.2725 | acc 0.9172 | f1 0.7881 | prec 0.8005 | recall 0.7761 | roc auc 0.9321 | pr auc 0.8771 | elapsed 91.89s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0811 | val loss 0.2764 | acc 0.9175 | f1 0.7901 | prec 0.7979 | recall 0.7824 | roc auc 0.9338 | pr auc 0.8800 | elapsed 91.91s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0769 | val loss 0.2827 | acc 0.9169 | f1 0.7907 | prec 0.7906 | recall 0.7909 | roc auc 0.9352 | pr auc 0.8818 | elapsed 91.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 02:58:51,768] Trial 12 finished with value: 15.345941719001715 and parameters: {'identity_weight': 12, 'decay': 940}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prc:  0.8818051545980581\n",
      "roc:  0.9351587788368558\n",
      "acc:  0.9169375\n",
      "train epoch 00/15 | batch 2001/2000 | loss 0.9500 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 33.12s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7048 | val loss 0.4808 | acc 0.8308 | f1 0.3057 | prec 0.8232 | recall 0.1877 | roc auc 0.6479 | pr auc 0.4530 | elapsed 89.10s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4550 | val loss 0.4028 | acc 0.8438 | f1 0.4861 | prec 0.7002 | recall 0.3723 | roc auc 0.7699 | pr auc 0.5927 | elapsed 91.30s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3326 | val loss 0.3771 | acc 0.8607 | f1 0.5870 | prec 0.7129 | recall 0.4989 | roc auc 0.8118 | pr auc 0.6710 | elapsed 92.00s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2568 | val loss 0.3508 | acc 0.8747 | f1 0.6451 | prec 0.7365 | recall 0.5739 | roc auc 0.8415 | pr auc 0.7282 | elapsed 87.04s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2070 | val loss 0.3313 | acc 0.8829 | f1 0.6800 | prec 0.7426 | recall 0.6271 | roc auc 0.8640 | pr auc 0.7663 | elapsed 89.37s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1719 | val loss 0.3170 | acc 0.8893 | f1 0.7069 | prec 0.7448 | recall 0.6728 | roc auc 0.8820 | pr auc 0.7944 | elapsed 91.16s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1448 | val loss 0.3015 | acc 0.8967 | f1 0.7298 | prec 0.7587 | recall 0.7030 | roc auc 0.8967 | pr auc 0.8180 | elapsed 91.29s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1271 | val loss 0.2899 | acc 0.9014 | f1 0.7460 | prec 0.7633 | recall 0.7294 | roc auc 0.9078 | pr auc 0.8354 | elapsed 88.96s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1147 | val loss 0.2803 | acc 0.9063 | f1 0.7597 | prec 0.7737 | recall 0.7461 | roc auc 0.9159 | pr auc 0.8492 | elapsed 88.48s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1051 | val loss 0.2748 | acc 0.9108 | f1 0.7705 | prec 0.7871 | recall 0.7546 | roc auc 0.9221 | pr auc 0.8598 | elapsed 88.84s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0975 | val loss 0.2731 | acc 0.9116 | f1 0.7750 | prec 0.7826 | recall 0.7676 | roc auc 0.9270 | pr auc 0.8674 | elapsed 89.93s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0912 | val loss 0.2733 | acc 0.9134 | f1 0.7803 | prec 0.7861 | recall 0.7745 | roc auc 0.9300 | pr auc 0.8727 | elapsed 90.66s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0858 | val loss 0.2724 | acc 0.9173 | f1 0.7884 | prec 0.8004 | recall 0.7767 | roc auc 0.9322 | pr auc 0.8772 | elapsed 90.41s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0811 | val loss 0.2763 | acc 0.9175 | f1 0.7901 | prec 0.7979 | recall 0.7824 | roc auc 0.9339 | pr auc 0.8800 | elapsed 90.72s\n",
      "train epoch 15/15 | batch 2000/2000 | loss 0.0769 | elapsed 85.20s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 03:21:55,060] Trial 13 finished with value: 15.346269574890714 and parameters: {'identity_weight': 12, 'decay': 941}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 15/15 | batch 2001/2000 | loss 0.0769 | val loss 0.2827 | acc 0.9168 | f1 0.7906 | prec 0.7899 | recall 0.7912 | roc auc 0.9352 | pr auc 0.8818 | elapsed 87.74s\n",
      "prc:  0.8818337970041976\n",
      "roc:  0.9351865174747893\n",
      "acc:  0.9168125\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.1824 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 30.86s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.8480 | val loss 0.4759 | acc 0.8289 | f1 0.3429 | prec 0.7212 | recall 0.2249 | roc auc 0.6628 | pr auc 0.4674 | elapsed 88.84s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5212 | val loss 0.4009 | acc 0.8435 | f1 0.5069 | prec 0.6763 | recall 0.4054 | roc auc 0.7752 | pr auc 0.6036 | elapsed 91.21s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3663 | val loss 0.3779 | acc 0.8592 | f1 0.5993 | prec 0.6888 | recall 0.5304 | roc auc 0.8177 | pr auc 0.6800 | elapsed 90.77s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2602 | val loss 0.3589 | acc 0.8700 | f1 0.6486 | prec 0.6995 | recall 0.6047 | roc auc 0.8463 | pr auc 0.7312 | elapsed 90.96s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1983 | val loss 0.3359 | acc 0.8792 | f1 0.6813 | prec 0.7153 | recall 0.6504 | roc auc 0.8677 | pr auc 0.7706 | elapsed 91.44s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1684 | val loss 0.3211 | acc 0.8851 | f1 0.7043 | prec 0.7198 | recall 0.6894 | roc auc 0.8836 | pr auc 0.7976 | elapsed 89.61s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1471 | val loss 0.3055 | acc 0.8922 | f1 0.7240 | prec 0.7362 | recall 0.7121 | roc auc 0.8962 | pr auc 0.8189 | elapsed 88.62s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1312 | val loss 0.2976 | acc 0.8951 | f1 0.7360 | prec 0.7353 | recall 0.7367 | roc auc 0.9065 | pr auc 0.8343 | elapsed 89.50s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1191 | val loss 0.2894 | acc 0.8997 | f1 0.7480 | prec 0.7458 | recall 0.7502 | roc auc 0.9141 | pr auc 0.8463 | elapsed 88.64s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1098 | val loss 0.2835 | acc 0.9027 | f1 0.7556 | prec 0.7531 | recall 0.7581 | roc auc 0.9201 | pr auc 0.8558 | elapsed 88.96s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1024 | val loss 0.2825 | acc 0.9018 | f1 0.7559 | prec 0.7459 | recall 0.7663 | roc auc 0.9248 | pr auc 0.8626 | elapsed 86.96s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0962 | val loss 0.2823 | acc 0.9035 | f1 0.7608 | prec 0.7487 | recall 0.7732 | roc auc 0.9278 | pr auc 0.8674 | elapsed 89.08s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0908 | val loss 0.2810 | acc 0.9074 | f1 0.7689 | prec 0.7613 | recall 0.7767 | roc auc 0.9302 | pr auc 0.8716 | elapsed 90.03s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0861 | val loss 0.2857 | acc 0.9075 | f1 0.7707 | prec 0.7585 | recall 0.7833 | roc auc 0.9320 | pr auc 0.8740 | elapsed 87.92s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0818 | val loss 0.2945 | acc 0.9061 | f1 0.7701 | prec 0.7490 | recall 0.7924 | roc auc 0.9332 | pr auc 0.8755 | elapsed 89.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 03:44:51,338] Trial 14 finished with value: 15.260471480923265 and parameters: {'identity_weight': 28, 'decay': 973}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prc:  0.8755207520661719\n",
      "roc:  0.9331898267102576\n",
      "acc:  0.906125\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.7054 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 30.61s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 1.1348 | val loss 0.4764 | acc 0.8251 | f1 0.3664 | prec 0.6519 | recall 0.2548 | roc auc 0.6686 | pr auc 0.4716 | elapsed 85.97s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.6516 | val loss 0.4046 | acc 0.8427 | f1 0.5219 | prec 0.6579 | recall 0.4324 | roc auc 0.7748 | pr auc 0.6044 | elapsed 89.09s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.4357 | val loss 0.3827 | acc 0.8550 | f1 0.6021 | prec 0.6610 | recall 0.5528 | roc auc 0.8180 | pr auc 0.6814 | elapsed 89.23s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2743 | val loss 0.3617 | acc 0.8659 | f1 0.6468 | prec 0.6774 | recall 0.6189 | roc auc 0.8471 | pr auc 0.7342 | elapsed 89.46s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2039 | val loss 0.3399 | acc 0.8743 | f1 0.6746 | prec 0.6936 | recall 0.6567 | roc auc 0.8681 | pr auc 0.7726 | elapsed 90.13s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1711 | val loss 0.3286 | acc 0.8801 | f1 0.6981 | prec 0.6974 | recall 0.6989 | roc auc 0.8833 | pr auc 0.7981 | elapsed 90.13s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1487 | val loss 0.3147 | acc 0.8869 | f1 0.7174 | prec 0.7117 | recall 0.7231 | roc auc 0.8952 | pr auc 0.8177 | elapsed 90.21s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1325 | val loss 0.3079 | acc 0.8895 | f1 0.7277 | prec 0.7120 | recall 0.7443 | roc auc 0.9048 | pr auc 0.8320 | elapsed 89.08s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1206 | val loss 0.3000 | acc 0.8943 | f1 0.7396 | prec 0.7236 | recall 0.7562 | roc auc 0.9118 | pr auc 0.8430 | elapsed 89.49s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1111 | val loss 0.2939 | acc 0.8995 | f1 0.7507 | prec 0.7392 | recall 0.7625 | roc auc 0.9174 | pr auc 0.8518 | elapsed 89.53s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1035 | val loss 0.2941 | acc 0.8988 | f1 0.7516 | prec 0.7328 | recall 0.7713 | roc auc 0.9220 | pr auc 0.8583 | elapsed 88.76s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0971 | val loss 0.2941 | acc 0.8997 | f1 0.7540 | prec 0.7343 | recall 0.7748 | roc auc 0.9248 | pr auc 0.8627 | elapsed 87.73s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0913 | val loss 0.2931 | acc 0.9031 | f1 0.7618 | prec 0.7438 | recall 0.7808 | roc auc 0.9272 | pr auc 0.8667 | elapsed 89.88s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0863 | val loss 0.2981 | acc 0.9036 | f1 0.7642 | prec 0.7423 | recall 0.7874 | roc auc 0.9291 | pr auc 0.8691 | elapsed 89.62s\n",
      "train epoch 15/15 | batch 2000/2000 | loss 0.0817 | elapsed 85.01s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 04:07:40,955] Trial 15 finished with value: 15.187968423656331 and parameters: {'identity_weight': 64, 'decay': 929}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 15/15 | batch 2001/2000 | loss 0.0817 | val loss 0.3085 | acc 0.9007 | f1 0.7607 | prec 0.7288 | recall 0.7956 | roc auc 0.9304 | pr auc 0.8705 | elapsed 87.64s\n",
      "prc:  0.8705171129485866\n",
      "roc:  0.9303516323617442\n",
      "acc:  0.9006875\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.0807 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.00s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7805 | val loss 0.4779 | acc 0.8297 | f1 0.3310 | prec 0.7506 | recall 0.2123 | roc auc 0.6574 | pr auc 0.4626 | elapsed 86.95s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4862 | val loss 0.4009 | acc 0.8436 | f1 0.4980 | prec 0.6860 | recall 0.3909 | roc auc 0.7736 | pr auc 0.6006 | elapsed 87.21s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3473 | val loss 0.3759 | acc 0.8612 | f1 0.5972 | prec 0.7043 | recall 0.5184 | roc auc 0.8160 | pr auc 0.6778 | elapsed 88.99s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2590 | val loss 0.3529 | acc 0.8732 | f1 0.6494 | prec 0.7198 | recall 0.5915 | roc auc 0.8454 | pr auc 0.7322 | elapsed 90.26s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1982 | val loss 0.3352 | acc 0.8807 | f1 0.6827 | prec 0.7227 | recall 0.6469 | roc auc 0.8671 | pr auc 0.7687 | elapsed 90.93s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1648 | val loss 0.3184 | acc 0.8872 | f1 0.7063 | prec 0.7310 | recall 0.6831 | roc auc 0.8835 | pr auc 0.7968 | elapsed 88.94s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1437 | val loss 0.3018 | acc 0.8952 | f1 0.7281 | prec 0.7508 | recall 0.7068 | roc auc 0.8966 | pr auc 0.8192 | elapsed 88.93s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1278 | val loss 0.2926 | acc 0.8974 | f1 0.7381 | prec 0.7477 | recall 0.7288 | roc auc 0.9072 | pr auc 0.8355 | elapsed 87.56s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1156 | val loss 0.2837 | acc 0.9034 | f1 0.7549 | prec 0.7605 | recall 0.7493 | roc auc 0.9151 | pr auc 0.8484 | elapsed 90.29s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1061 | val loss 0.2781 | acc 0.9075 | f1 0.7647 | prec 0.7721 | recall 0.7575 | roc auc 0.9213 | pr auc 0.8584 | elapsed 88.28s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0985 | val loss 0.2766 | acc 0.9081 | f1 0.7685 | prec 0.7681 | recall 0.7688 | roc auc 0.9261 | pr auc 0.8656 | elapsed 89.28s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0921 | val loss 0.2765 | acc 0.9093 | f1 0.7722 | prec 0.7693 | recall 0.7751 | roc auc 0.9292 | pr auc 0.8707 | elapsed 89.30s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0867 | val loss 0.2751 | acc 0.9126 | f1 0.7794 | prec 0.7809 | recall 0.7780 | roc auc 0.9314 | pr auc 0.8750 | elapsed 90.18s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0819 | val loss 0.2791 | acc 0.9126 | f1 0.7804 | prec 0.7784 | recall 0.7824 | roc auc 0.9331 | pr auc 0.8777 | elapsed 89.79s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0776 | val loss 0.2864 | acc 0.9122 | f1 0.7813 | prec 0.7723 | recall 0.7906 | roc auc 0.9343 | pr auc 0.8793 | elapsed 88.53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 04:30:31,478] Trial 16 finished with value: 15.311373449887563 and parameters: {'identity_weight': 21, 'decay': 934}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prc:  0.879308720696727\n",
      "roc:  0.9343497904867154\n",
      "acc:  0.9121875\n",
      "train epoch 00/15 | batch 2001/2000 | loss 2.2284 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.70s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 1.4085 | val loss 0.4804 | acc 0.8203 | f1 0.3731 | prec 0.6058 | recall 0.2696 | roc auc 0.6677 | pr auc 0.4702 | elapsed 87.25s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.7763 | val loss 0.4097 | acc 0.8387 | f1 0.5206 | prec 0.6348 | recall 0.4413 | roc auc 0.7714 | pr auc 0.5998 | elapsed 87.78s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.5041 | val loss 0.3871 | acc 0.8514 | f1 0.5987 | prec 0.6449 | recall 0.5587 | roc auc 0.8160 | pr auc 0.6794 | elapsed 88.69s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.3021 | val loss 0.3678 | acc 0.8623 | f1 0.6442 | prec 0.6611 | recall 0.6280 | roc auc 0.8458 | pr auc 0.7328 | elapsed 87.60s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2092 | val loss 0.3460 | acc 0.8716 | f1 0.6729 | prec 0.6802 | recall 0.6658 | roc auc 0.8670 | pr auc 0.7719 | elapsed 89.10s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1732 | val loss 0.3368 | acc 0.8778 | f1 0.6981 | prec 0.6845 | recall 0.7121 | roc auc 0.8821 | pr auc 0.7972 | elapsed 87.73s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1500 | val loss 0.3222 | acc 0.8849 | f1 0.7148 | prec 0.7030 | recall 0.7269 | roc auc 0.8935 | pr auc 0.8161 | elapsed 86.59s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1335 | val loss 0.3157 | acc 0.8862 | f1 0.7222 | prec 0.7006 | recall 0.7452 | roc auc 0.9029 | pr auc 0.8301 | elapsed 89.21s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1209 | val loss 0.3079 | acc 0.8903 | f1 0.7324 | prec 0.7098 | recall 0.7565 | roc auc 0.9099 | pr auc 0.8407 | elapsed 87.40s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1109 | val loss 0.3017 | acc 0.8956 | f1 0.7433 | prec 0.7259 | recall 0.7616 | roc auc 0.9154 | pr auc 0.8493 | elapsed 88.30s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1028 | val loss 0.3025 | acc 0.8955 | f1 0.7459 | prec 0.7207 | recall 0.7729 | roc auc 0.9201 | pr auc 0.8557 | elapsed 90.24s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0959 | val loss 0.3024 | acc 0.8968 | f1 0.7490 | prec 0.7235 | recall 0.7764 | roc auc 0.9229 | pr auc 0.8600 | elapsed 89.93s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0897 | val loss 0.3014 | acc 0.8998 | f1 0.7553 | prec 0.7323 | recall 0.7798 | roc auc 0.9254 | pr auc 0.8639 | elapsed 86.98s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0842 | val loss 0.3073 | acc 0.9007 | f1 0.7591 | prec 0.7319 | recall 0.7883 | roc auc 0.9272 | pr auc 0.8662 | elapsed 88.59s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0792 | val loss 0.3183 | acc 0.8997 | f1 0.7593 | prec 0.7247 | recall 0.7975 | roc auc 0.9285 | pr auc 0.8677 | elapsed 88.79s\n",
      "prc:  0.8676626635251712\n",
      "roc:  0.928535703212537\n",
      "acc:  0.8996875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 04:53:11,381] Trial 17 finished with value: 15.147528354526933 and parameters: {'identity_weight': 100, 'decay': 902}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 1.2551 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.62s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.8875 | val loss 0.4754 | acc 0.8284 | f1 0.3469 | prec 0.7091 | recall 0.2296 | roc auc 0.6647 | pr auc 0.4689 | elapsed 87.73s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5382 | val loss 0.4011 | acc 0.8433 | f1 0.5103 | prec 0.6713 | recall 0.4117 | roc auc 0.7756 | pr auc 0.6045 | elapsed 88.46s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3733 | val loss 0.3789 | acc 0.8582 | f1 0.5996 | prec 0.6822 | recall 0.5348 | roc auc 0.8180 | pr auc 0.6805 | elapsed 87.97s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2593 | val loss 0.3590 | acc 0.8698 | f1 0.6496 | prec 0.6971 | recall 0.6082 | roc auc 0.8465 | pr auc 0.7321 | elapsed 89.16s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1987 | val loss 0.3366 | acc 0.8787 | f1 0.6809 | prec 0.7122 | recall 0.6523 | roc auc 0.8677 | pr auc 0.7709 | elapsed 87.68s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1686 | val loss 0.3223 | acc 0.8836 | f1 0.7016 | prec 0.7138 | recall 0.6898 | roc auc 0.8834 | pr auc 0.7976 | elapsed 89.42s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1472 | val loss 0.3071 | acc 0.8911 | f1 0.7219 | prec 0.7320 | recall 0.7121 | roc auc 0.8959 | pr auc 0.8185 | elapsed 87.38s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1312 | val loss 0.2995 | acc 0.8939 | f1 0.7334 | prec 0.7313 | recall 0.7354 | roc auc 0.9060 | pr auc 0.8337 | elapsed 88.56s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1191 | val loss 0.2914 | acc 0.8985 | f1 0.7460 | prec 0.7409 | recall 0.7512 | roc auc 0.9136 | pr auc 0.8455 | elapsed 88.54s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1098 | val loss 0.2853 | acc 0.9022 | f1 0.7552 | prec 0.7507 | recall 0.7597 | roc auc 0.9195 | pr auc 0.8548 | elapsed 87.16s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1024 | val loss 0.2844 | acc 0.9014 | f1 0.7554 | prec 0.7442 | recall 0.7669 | roc auc 0.9242 | pr auc 0.8617 | elapsed 87.97s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0962 | val loss 0.2842 | acc 0.9030 | f1 0.7593 | prec 0.7479 | recall 0.7710 | roc auc 0.9273 | pr auc 0.8665 | elapsed 89.57s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0907 | val loss 0.2829 | acc 0.9058 | f1 0.7657 | prec 0.7560 | recall 0.7757 | roc auc 0.9296 | pr auc 0.8706 | elapsed 88.85s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0859 | val loss 0.2874 | acc 0.9062 | f1 0.7677 | prec 0.7547 | recall 0.7811 | roc auc 0.9315 | pr auc 0.8731 | elapsed 87.83s\n",
      "train epoch 15/15 | batch 2000/2000 | loss 0.0816 | elapsed 86.00s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 05:15:52,129] Trial 18 finished with value: 15.248121535015038 and parameters: {'identity_weight': 33, 'decay': 960}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 15/15 | batch 2001/2000 | loss 0.0816 | val loss 0.2963 | acc 0.9051 | f1 0.7677 | prec 0.7465 | recall 0.7902 | roc auc 0.9327 | pr auc 0.8747 | elapsed 88.77s\n",
      "prc:  0.8746608009896468\n",
      "roc:  0.932731420853095\n",
      "acc:  0.905125\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.0372 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.26s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7564 | val loss 0.4769 | acc 0.8311 | f1 0.3258 | prec 0.7839 | recall 0.2057 | roc auc 0.6569 | pr auc 0.4618 | elapsed 86.65s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4767 | val loss 0.4012 | acc 0.8437 | f1 0.4953 | prec 0.6893 | recall 0.3865 | roc auc 0.7731 | pr auc 0.5988 | elapsed 87.66s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3440 | val loss 0.3763 | acc 0.8608 | f1 0.5942 | prec 0.7045 | recall 0.5137 | roc auc 0.8153 | pr auc 0.6763 | elapsed 88.46s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2596 | val loss 0.3525 | acc 0.8736 | f1 0.6487 | prec 0.7229 | recall 0.5883 | roc auc 0.8449 | pr auc 0.7314 | elapsed 89.11s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2012 | val loss 0.3366 | acc 0.8807 | f1 0.6821 | prec 0.7237 | recall 0.6450 | roc auc 0.8669 | pr auc 0.7676 | elapsed 88.84s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1652 | val loss 0.3188 | acc 0.8872 | f1 0.7064 | prec 0.7305 | recall 0.6838 | roc auc 0.8835 | pr auc 0.7962 | elapsed 88.33s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1441 | val loss 0.3019 | acc 0.8957 | f1 0.7285 | prec 0.7534 | recall 0.7052 | roc auc 0.8967 | pr auc 0.8190 | elapsed 89.14s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1281 | val loss 0.2924 | acc 0.8984 | f1 0.7403 | prec 0.7511 | recall 0.7298 | roc auc 0.9074 | pr auc 0.8354 | elapsed 88.81s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1159 | val loss 0.2834 | acc 0.9042 | f1 0.7564 | prec 0.7633 | recall 0.7496 | roc auc 0.9154 | pr auc 0.8485 | elapsed 88.07s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1063 | val loss 0.2778 | acc 0.9078 | f1 0.7655 | prec 0.7730 | recall 0.7581 | roc auc 0.9216 | pr auc 0.8587 | elapsed 89.01s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0988 | val loss 0.2764 | acc 0.9084 | f1 0.7694 | prec 0.7690 | recall 0.7698 | roc auc 0.9265 | pr auc 0.8660 | elapsed 87.93s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0924 | val loss 0.2762 | acc 0.9095 | f1 0.7728 | prec 0.7699 | recall 0.7757 | roc auc 0.9295 | pr auc 0.8712 | elapsed 86.39s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0870 | val loss 0.2748 | acc 0.9131 | f1 0.7806 | prec 0.7823 | recall 0.7789 | roc auc 0.9317 | pr auc 0.8756 | elapsed 85.77s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0822 | val loss 0.2788 | acc 0.9127 | f1 0.7806 | prec 0.7785 | recall 0.7827 | roc auc 0.9335 | pr auc 0.8783 | elapsed 88.09s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0779 | val loss 0.2859 | acc 0.9127 | f1 0.7826 | prec 0.7739 | recall 0.7915 | roc auc 0.9347 | pr auc 0.8800 | elapsed 88.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 05:38:27,910] Trial 19 finished with value: 15.320947296851827 and parameters: {'identity_weight': 18, 'decay': 947}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prc:  0.8799804977470697\n",
      "roc:  0.9347320532301884\n",
      "acc:  0.91275\n",
      "train epoch 00/15 | batch 2001/2000 | loss 0.9355 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 30.70s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7017 | val loss 0.4811 | acc 0.8307 | f1 0.3039 | prec 0.8266 | recall 0.1861 | roc auc 0.6472 | pr auc 0.4522 | elapsed 84.56s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4569 | val loss 0.4029 | acc 0.8438 | f1 0.4863 | prec 0.7000 | recall 0.3726 | roc auc 0.7698 | pr auc 0.5926 | elapsed 88.40s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3358 | val loss 0.3771 | acc 0.8606 | f1 0.5874 | prec 0.7115 | recall 0.5002 | roc auc 0.8121 | pr auc 0.6711 | elapsed 86.88s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2603 | val loss 0.3511 | acc 0.8747 | f1 0.6461 | prec 0.7349 | recall 0.5764 | roc auc 0.8420 | pr auc 0.7284 | elapsed 85.05s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2094 | val loss 0.3323 | acc 0.8822 | f1 0.6797 | prec 0.7380 | recall 0.6299 | roc auc 0.8647 | pr auc 0.7665 | elapsed 88.12s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1717 | val loss 0.3198 | acc 0.8871 | f1 0.7032 | prec 0.7347 | recall 0.6743 | roc auc 0.8828 | pr auc 0.7943 | elapsed 88.26s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1454 | val loss 0.3006 | acc 0.8970 | f1 0.7306 | prec 0.7594 | recall 0.7039 | roc auc 0.8967 | pr auc 0.8184 | elapsed 86.70s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1293 | val loss 0.2900 | acc 0.9006 | f1 0.7445 | prec 0.7599 | recall 0.7298 | roc auc 0.9078 | pr auc 0.8357 | elapsed 86.92s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1170 | val loss 0.2806 | acc 0.9059 | f1 0.7594 | prec 0.7711 | recall 0.7480 | roc auc 0.9160 | pr auc 0.8493 | elapsed 87.89s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1075 | val loss 0.2750 | acc 0.9098 | f1 0.7694 | prec 0.7810 | recall 0.7581 | roc auc 0.9222 | pr auc 0.8597 | elapsed 88.50s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0999 | val loss 0.2737 | acc 0.9103 | f1 0.7731 | prec 0.7762 | recall 0.7701 | roc auc 0.9271 | pr auc 0.8671 | elapsed 87.54s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0937 | val loss 0.2738 | acc 0.9124 | f1 0.7788 | prec 0.7803 | recall 0.7773 | roc auc 0.9301 | pr auc 0.8723 | elapsed 85.87s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0884 | val loss 0.2724 | acc 0.9147 | f1 0.7834 | prec 0.7899 | recall 0.7770 | roc auc 0.9323 | pr auc 0.8768 | elapsed 87.56s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0837 | val loss 0.2764 | acc 0.9148 | f1 0.7852 | prec 0.7858 | recall 0.7846 | roc auc 0.9341 | pr auc 0.8795 | elapsed 87.30s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0795 | val loss 0.2834 | acc 0.9147 | f1 0.7872 | prec 0.7795 | recall 0.7950 | roc auc 0.9353 | pr auc 0.8811 | elapsed 87.24s\n",
      "prc:  0.8811150673866497\n",
      "roc:  0.9353297171186934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 06:00:48,440] Trial 20 finished with value: 15.337816476578656 and parameters: {'identity_weight': 11, 'decay': 995}. Best is trial 10 with value: 15.349425072967554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9146875\n",
      "train epoch 00/15 | batch 2001/2000 | loss 0.9209 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 31.55s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.6875 | val loss 0.4828 | acc 0.8307 | f1 0.2954 | prec 0.8478 | recall 0.1789 | roc auc 0.6433 | pr auc 0.4480 | elapsed 84.96s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4483 | val loss 0.4037 | acc 0.8436 | f1 0.4815 | prec 0.7034 | recall 0.3660 | roc auc 0.7683 | pr auc 0.5897 | elapsed 85.89s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3289 | val loss 0.3779 | acc 0.8598 | f1 0.5812 | prec 0.7132 | recall 0.4904 | roc auc 0.8100 | pr auc 0.6681 | elapsed 86.95s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2552 | val loss 0.3512 | acc 0.8752 | f1 0.6432 | prec 0.7437 | recall 0.5666 | roc auc 0.8395 | pr auc 0.7258 | elapsed 82.69s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2075 | val loss 0.3310 | acc 0.8844 | f1 0.6807 | prec 0.7530 | recall 0.6211 | roc auc 0.8619 | pr auc 0.7639 | elapsed 86.11s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1746 | val loss 0.3152 | acc 0.8909 | f1 0.7070 | prec 0.7566 | recall 0.6636 | roc auc 0.8801 | pr auc 0.7924 | elapsed 89.62s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1494 | val loss 0.2991 | acc 0.8989 | f1 0.7320 | prec 0.7719 | recall 0.6961 | roc auc 0.8954 | pr auc 0.8169 | elapsed 87.13s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1290 | val loss 0.2909 | acc 0.9012 | f1 0.7455 | prec 0.7629 | recall 0.7288 | roc auc 0.9079 | pr auc 0.8350 | elapsed 85.89s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1144 | val loss 0.2802 | acc 0.9076 | f1 0.7619 | prec 0.7798 | recall 0.7449 | roc auc 0.9160 | pr auc 0.8492 | elapsed 84.62s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1048 | val loss 0.2744 | acc 0.9121 | f1 0.7729 | prec 0.7934 | recall 0.7534 | roc auc 0.9222 | pr auc 0.8599 | elapsed 84.52s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0971 | val loss 0.2723 | acc 0.9128 | f1 0.7771 | prec 0.7886 | recall 0.7660 | roc auc 0.9270 | pr auc 0.8676 | elapsed 87.99s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0908 | val loss 0.2726 | acc 0.9143 | f1 0.7818 | prec 0.7902 | recall 0.7735 | roc auc 0.9301 | pr auc 0.8730 | elapsed 88.64s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0854 | val loss 0.2720 | acc 0.9178 | f1 0.7891 | prec 0.8039 | recall 0.7748 | roc auc 0.9322 | pr auc 0.8776 | elapsed 89.16s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0808 | val loss 0.2757 | acc 0.9186 | f1 0.7921 | prec 0.8027 | recall 0.7817 | roc auc 0.9339 | pr auc 0.8804 | elapsed 85.08s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0766 | val loss 0.2819 | acc 0.9181 | f1 0.7932 | prec 0.7946 | recall 0.7918 | roc auc 0.9352 | pr auc 0.8823 | elapsed 87.98s\n",
      "prc:  0.882277778038924\n",
      "roc:  0.9352139122960506\n",
      "acc:  0.9180625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 06:23:00,257] Trial 21 finished with value: 15.352123754165543 and parameters: {'identity_weight': 10, 'decay': 937}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 1.1824 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 31.69s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.8390 | val loss 0.4761 | acc 0.8289 | f1 0.3409 | prec 0.7232 | recall 0.2230 | roc auc 0.6623 | pr auc 0.4669 | elapsed 85.43s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5127 | val loss 0.4008 | acc 0.8436 | f1 0.5058 | prec 0.6778 | recall 0.4035 | roc auc 0.7749 | pr auc 0.6032 | elapsed 85.18s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3600 | val loss 0.3772 | acc 0.8598 | f1 0.5993 | prec 0.6920 | recall 0.5285 | roc auc 0.8174 | pr auc 0.6798 | elapsed 86.39s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2592 | val loss 0.3574 | acc 0.8703 | f1 0.6478 | prec 0.7025 | recall 0.6009 | roc auc 0.8462 | pr auc 0.7316 | elapsed 89.80s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1962 | val loss 0.3356 | acc 0.8794 | f1 0.6809 | prec 0.7167 | recall 0.6485 | roc auc 0.8675 | pr auc 0.7701 | elapsed 87.50s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1661 | val loss 0.3203 | acc 0.8857 | f1 0.7042 | prec 0.7237 | recall 0.6857 | roc auc 0.8835 | pr auc 0.7974 | elapsed 86.62s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1449 | val loss 0.3043 | acc 0.8939 | f1 0.7267 | prec 0.7432 | recall 0.7109 | roc auc 0.8963 | pr auc 0.8189 | elapsed 85.85s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1289 | val loss 0.2960 | acc 0.8959 | f1 0.7362 | prec 0.7402 | recall 0.7323 | roc auc 0.9066 | pr auc 0.8346 | elapsed 87.41s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1167 | val loss 0.2873 | acc 0.9012 | f1 0.7506 | prec 0.7519 | recall 0.7493 | roc auc 0.9144 | pr auc 0.8470 | elapsed 87.26s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1073 | val loss 0.2814 | acc 0.9041 | f1 0.7580 | prec 0.7592 | recall 0.7569 | roc auc 0.9204 | pr auc 0.8567 | elapsed 87.47s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0997 | val loss 0.2803 | acc 0.9044 | f1 0.7610 | prec 0.7554 | recall 0.7666 | roc auc 0.9252 | pr auc 0.8638 | elapsed 83.83s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0934 | val loss 0.2800 | acc 0.9064 | f1 0.7663 | prec 0.7598 | recall 0.7729 | roc auc 0.9283 | pr auc 0.8687 | elapsed 86.95s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0879 | val loss 0.2783 | acc 0.9090 | f1 0.7716 | prec 0.7685 | recall 0.7748 | roc auc 0.9306 | pr auc 0.8731 | elapsed 85.68s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0831 | val loss 0.2823 | acc 0.9099 | f1 0.7752 | prec 0.7681 | recall 0.7824 | roc auc 0.9324 | pr auc 0.8756 | elapsed 83.30s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0788 | val loss 0.2899 | acc 0.9093 | f1 0.7754 | prec 0.7623 | recall 0.7890 | roc auc 0.9337 | pr auc 0.8772 | elapsed 86.35s\n",
      "prc:  0.8772389347140096\n",
      "roc:  0.9337194148976992\n",
      "acc:  0.9093125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 06:45:10,034] Trial 22 finished with value: 15.284018336526293 and parameters: {'identity_weight': 28, 'decay': 937}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 1.0517 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 31.16s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7617 | val loss 0.4767 | acc 0.8311 | f1 0.3272 | prec 0.7812 | recall 0.2069 | roc auc 0.6574 | pr auc 0.4623 | elapsed 86.15s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4772 | val loss 0.4010 | acc 0.8438 | f1 0.4958 | prec 0.6893 | recall 0.3871 | roc auc 0.7732 | pr auc 0.5991 | elapsed 85.74s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3432 | val loss 0.3762 | acc 0.8608 | f1 0.5941 | prec 0.7050 | recall 0.5134 | roc auc 0.8153 | pr auc 0.6765 | elapsed 86.03s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2586 | val loss 0.3523 | acc 0.8738 | f1 0.6492 | prec 0.7240 | recall 0.5883 | roc auc 0.8448 | pr auc 0.7316 | elapsed 86.84s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2008 | val loss 0.3367 | acc 0.8807 | f1 0.6820 | prec 0.7238 | recall 0.6447 | roc auc 0.8668 | pr auc 0.7675 | elapsed 87.22s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1644 | val loss 0.3189 | acc 0.8868 | f1 0.7054 | prec 0.7295 | recall 0.6828 | roc auc 0.8834 | pr auc 0.7961 | elapsed 88.31s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1433 | val loss 0.3020 | acc 0.8958 | f1 0.7287 | prec 0.7539 | recall 0.7052 | roc auc 0.8967 | pr auc 0.8188 | elapsed 86.07s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1273 | val loss 0.2924 | acc 0.8988 | f1 0.7410 | prec 0.7524 | recall 0.7301 | roc auc 0.9073 | pr auc 0.8353 | elapsed 86.01s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1151 | val loss 0.2833 | acc 0.9041 | f1 0.7559 | prec 0.7639 | recall 0.7480 | roc auc 0.9154 | pr auc 0.8485 | elapsed 87.68s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1055 | val loss 0.2777 | acc 0.9081 | f1 0.7659 | prec 0.7741 | recall 0.7578 | roc auc 0.9216 | pr auc 0.8587 | elapsed 87.85s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0979 | val loss 0.2762 | acc 0.9090 | f1 0.7703 | prec 0.7716 | recall 0.7691 | roc auc 0.9264 | pr auc 0.8661 | elapsed 85.57s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0915 | val loss 0.2760 | acc 0.9104 | f1 0.7744 | prec 0.7737 | recall 0.7751 | roc auc 0.9295 | pr auc 0.8713 | elapsed 85.64s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0861 | val loss 0.2748 | acc 0.9141 | f1 0.7824 | prec 0.7863 | recall 0.7786 | roc auc 0.9317 | pr auc 0.8757 | elapsed 86.23s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0813 | val loss 0.2786 | acc 0.9139 | f1 0.7829 | prec 0.7833 | recall 0.7824 | roc auc 0.9334 | pr auc 0.8785 | elapsed 86.03s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0770 | val loss 0.2855 | acc 0.9136 | f1 0.7841 | prec 0.7780 | recall 0.7902 | roc auc 0.9347 | pr auc 0.8802 | elapsed 86.95s\n",
      "prc:  0.8802152936309977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 07:07:22,497] Trial 23 finished with value: 15.32388564916166 and parameters: {'identity_weight': 19, 'decay': 927}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc:  0.9346846188086139\n",
      "acc:  0.913625\n",
      "train epoch 00/15 | batch 2001/2000 | loss 0.9209 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.39s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.6891 | val loss 0.4826 | acc 0.8306 | f1 0.2961 | prec 0.8444 | recall 0.1795 | roc auc 0.6438 | pr auc 0.4485 | elapsed 86.86s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4498 | val loss 0.4036 | acc 0.8436 | f1 0.4824 | prec 0.7028 | recall 0.3672 | roc auc 0.7685 | pr auc 0.5901 | elapsed 85.81s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3304 | val loss 0.3778 | acc 0.8600 | f1 0.5826 | prec 0.7134 | recall 0.4923 | roc auc 0.8104 | pr auc 0.6686 | elapsed 85.23s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2566 | val loss 0.3511 | acc 0.8752 | f1 0.6438 | prec 0.7427 | recall 0.5682 | roc auc 0.8400 | pr auc 0.7263 | elapsed 87.30s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2085 | val loss 0.3311 | acc 0.8841 | f1 0.6809 | prec 0.7507 | recall 0.6230 | roc auc 0.8626 | pr auc 0.7646 | elapsed 84.88s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1749 | val loss 0.3156 | acc 0.8904 | f1 0.7074 | prec 0.7525 | recall 0.6674 | roc auc 0.8808 | pr auc 0.7931 | elapsed 86.47s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1487 | val loss 0.3004 | acc 0.8979 | f1 0.7315 | prec 0.7653 | recall 0.7005 | roc auc 0.8961 | pr auc 0.8174 | elapsed 87.35s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1281 | val loss 0.2899 | acc 0.9019 | f1 0.7469 | prec 0.7649 | recall 0.7298 | roc auc 0.9079 | pr auc 0.8352 | elapsed 87.52s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1151 | val loss 0.2798 | acc 0.9072 | f1 0.7609 | prec 0.7783 | recall 0.7443 | roc auc 0.9160 | pr auc 0.8493 | elapsed 88.22s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1054 | val loss 0.2742 | acc 0.9116 | f1 0.7721 | prec 0.7907 | recall 0.7543 | roc auc 0.9222 | pr auc 0.8600 | elapsed 86.99s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0978 | val loss 0.2723 | acc 0.9124 | f1 0.7764 | prec 0.7864 | recall 0.7666 | roc auc 0.9271 | pr auc 0.8676 | elapsed 87.93s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0915 | val loss 0.2726 | acc 0.9135 | f1 0.7803 | prec 0.7866 | recall 0.7742 | roc auc 0.9301 | pr auc 0.8730 | elapsed 87.82s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0862 | val loss 0.2718 | acc 0.9177 | f1 0.7891 | prec 0.8033 | recall 0.7754 | roc auc 0.9323 | pr auc 0.8775 | elapsed 85.34s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0815 | val loss 0.2756 | acc 0.9183 | f1 0.7921 | prec 0.8001 | recall 0.7843 | roc auc 0.9340 | pr auc 0.8804 | elapsed 87.48s\n",
      "train epoch 15/15 | batch 2000/2000 | loss 0.0773 | elapsed 82.61s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 07:29:38,308] Trial 24 finished with value: 15.351652046764283 and parameters: {'identity_weight': 10, 'decay': 955}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 15/15 | batch 2001/2000 | loss 0.0773 | val loss 0.2818 | acc 0.9177 | f1 0.7927 | prec 0.7923 | recall 0.7931 | roc auc 0.9353 | pr auc 0.8822 | elapsed 85.17s\n",
      "prc:  0.8821873005575351\n",
      "roc:  0.9353485901981551\n",
      "acc:  0.9176875\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.2986 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 30.41s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.9119 | val loss 0.4752 | acc 0.8279 | f1 0.3493 | prec 0.6998 | recall 0.2328 | roc auc 0.6655 | pr auc 0.4696 | elapsed 86.11s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5493 | val loss 0.4013 | acc 0.8437 | f1 0.5135 | prec 0.6714 | recall 0.4157 | roc auc 0.7757 | pr auc 0.6049 | elapsed 87.35s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3784 | val loss 0.3795 | acc 0.8581 | f1 0.6005 | prec 0.6801 | recall 0.5376 | roc auc 0.8182 | pr auc 0.6808 | elapsed 87.01s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2595 | val loss 0.3593 | acc 0.8699 | f1 0.6508 | prec 0.6961 | recall 0.6110 | roc auc 0.8466 | pr auc 0.7325 | elapsed 87.21s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1993 | val loss 0.3371 | acc 0.8785 | f1 0.6808 | prec 0.7111 | recall 0.6529 | roc auc 0.8677 | pr auc 0.7711 | elapsed 85.58s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1689 | val loss 0.3231 | acc 0.8836 | f1 0.7016 | prec 0.7138 | recall 0.6898 | roc auc 0.8833 | pr auc 0.7975 | elapsed 87.54s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1475 | val loss 0.3082 | acc 0.8908 | f1 0.7212 | prec 0.7305 | recall 0.7121 | roc auc 0.8957 | pr auc 0.8182 | elapsed 87.01s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1314 | val loss 0.3007 | acc 0.8935 | f1 0.7330 | prec 0.7293 | recall 0.7367 | roc auc 0.9057 | pr auc 0.8332 | elapsed 83.83s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1194 | val loss 0.2928 | acc 0.8978 | f1 0.7446 | prec 0.7382 | recall 0.7512 | roc auc 0.9132 | pr auc 0.8449 | elapsed 87.89s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1100 | val loss 0.2866 | acc 0.9017 | f1 0.7539 | prec 0.7491 | recall 0.7587 | roc auc 0.9191 | pr auc 0.8542 | elapsed 87.28s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1026 | val loss 0.2858 | acc 0.9009 | f1 0.7542 | prec 0.7428 | recall 0.7660 | roc auc 0.9238 | pr auc 0.8610 | elapsed 87.17s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0964 | val loss 0.2856 | acc 0.9026 | f1 0.7586 | prec 0.7460 | recall 0.7717 | roc auc 0.9269 | pr auc 0.8658 | elapsed 86.90s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0909 | val loss 0.2844 | acc 0.9054 | f1 0.7648 | prec 0.7551 | recall 0.7748 | roc auc 0.9292 | pr auc 0.8699 | elapsed 85.80s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0861 | val loss 0.2889 | acc 0.9058 | f1 0.7669 | prec 0.7531 | recall 0.7811 | roc auc 0.9311 | pr auc 0.8724 | elapsed 87.00s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0818 | val loss 0.2979 | acc 0.9044 | f1 0.7661 | prec 0.7444 | recall 0.7890 | roc auc 0.9324 | pr auc 0.8739 | elapsed 86.25s\n",
      "prc:  0.8739114845522608\n",
      "roc:  0.93236011112646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 07:51:51,597] Trial 25 finished with value: 15.237650512281368 and parameters: {'identity_weight': 36, 'decay': 956}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.904375\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.1534 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 31.05s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.8307 | val loss 0.4763 | acc 0.8290 | f1 0.3404 | prec 0.7256 | recall 0.2224 | roc auc 0.6617 | pr auc 0.4664 | elapsed 84.63s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5131 | val loss 0.4008 | acc 0.8436 | f1 0.5059 | prec 0.6781 | recall 0.4035 | roc auc 0.7749 | pr auc 0.6030 | elapsed 86.91s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3624 | val loss 0.3775 | acc 0.8595 | f1 0.5990 | prec 0.6907 | recall 0.5288 | roc auc 0.8174 | pr auc 0.6796 | elapsed 88.08s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2604 | val loss 0.3584 | acc 0.8702 | f1 0.6483 | prec 0.7015 | recall 0.6025 | roc auc 0.8462 | pr auc 0.7310 | elapsed 87.86s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1978 | val loss 0.3356 | acc 0.8794 | f1 0.6811 | prec 0.7168 | recall 0.6488 | roc auc 0.8676 | pr auc 0.7703 | elapsed 87.03s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1680 | val loss 0.3204 | acc 0.8857 | f1 0.7048 | prec 0.7228 | recall 0.6876 | roc auc 0.8836 | pr auc 0.7975 | elapsed 87.13s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1468 | val loss 0.3047 | acc 0.8933 | f1 0.7259 | prec 0.7405 | recall 0.7118 | roc auc 0.8964 | pr auc 0.8190 | elapsed 86.92s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1308 | val loss 0.2966 | acc 0.8956 | f1 0.7363 | prec 0.7378 | recall 0.7348 | roc auc 0.9066 | pr auc 0.8346 | elapsed 84.28s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1187 | val loss 0.2882 | acc 0.9003 | f1 0.7492 | prec 0.7481 | recall 0.7502 | roc auc 0.9143 | pr auc 0.8467 | elapsed 86.17s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1094 | val loss 0.2824 | acc 0.9035 | f1 0.7571 | prec 0.7564 | recall 0.7578 | roc auc 0.9204 | pr auc 0.8563 | elapsed 87.48s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1019 | val loss 0.2814 | acc 0.9027 | f1 0.7578 | prec 0.7486 | recall 0.7672 | roc auc 0.9251 | pr auc 0.8632 | elapsed 84.00s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0957 | val loss 0.2811 | acc 0.9049 | f1 0.7635 | prec 0.7534 | recall 0.7739 | roc auc 0.9281 | pr auc 0.8680 | elapsed 83.15s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0903 | val loss 0.2797 | acc 0.9079 | f1 0.7700 | prec 0.7631 | recall 0.7770 | roc auc 0.9304 | pr auc 0.8722 | elapsed 84.09s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0856 | val loss 0.2843 | acc 0.9084 | f1 0.7726 | prec 0.7616 | recall 0.7839 | roc auc 0.9322 | pr auc 0.8747 | elapsed 87.70s\n",
      "train epoch 15/15 | batch 2000/2000 | loss 0.0813 | elapsed 84.27s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 08:13:57,988] Trial 26 finished with value: 15.269738634107474 and parameters: {'identity_weight': 26, 'decay': 973}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 15/15 | batch 2001/2000 | loss 0.0813 | val loss 0.2929 | acc 0.9074 | f1 0.7726 | prec 0.7532 | recall 0.7931 | roc auc 0.9335 | pr auc 0.8762 | elapsed 86.92s\n",
      "prc:  0.8761626147345951\n",
      "roc:  0.9334562477935873\n",
      "acc:  0.907375\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.0372 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 31.38s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7598 | val loss 0.4767 | acc 0.8313 | f1 0.3270 | prec 0.7838 | recall 0.2066 | roc auc 0.6572 | pr auc 0.4622 | elapsed 85.61s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4798 | val loss 0.4011 | acc 0.8436 | f1 0.4955 | prec 0.6881 | recall 0.3871 | roc auc 0.7733 | pr auc 0.5993 | elapsed 87.01s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3466 | val loss 0.3764 | acc 0.8610 | f1 0.5958 | prec 0.7043 | recall 0.5162 | roc auc 0.8156 | pr auc 0.6766 | elapsed 86.05s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2609 | val loss 0.3531 | acc 0.8732 | f1 0.6488 | prec 0.7202 | recall 0.5902 | roc auc 0.8452 | pr auc 0.7315 | elapsed 86.90s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2005 | val loss 0.3359 | acc 0.8802 | f1 0.6815 | prec 0.7216 | recall 0.6457 | roc auc 0.8671 | pr auc 0.7681 | elapsed 87.84s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1661 | val loss 0.3188 | acc 0.8871 | f1 0.7063 | prec 0.7297 | recall 0.6844 | roc auc 0.8836 | pr auc 0.7966 | elapsed 87.46s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1451 | val loss 0.3021 | acc 0.8955 | f1 0.7287 | prec 0.7516 | recall 0.7071 | roc auc 0.8968 | pr auc 0.8192 | elapsed 84.59s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1292 | val loss 0.2929 | acc 0.8974 | f1 0.7387 | prec 0.7465 | recall 0.7310 | roc auc 0.9074 | pr auc 0.8355 | elapsed 84.69s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1169 | val loss 0.2840 | acc 0.9028 | f1 0.7538 | prec 0.7578 | recall 0.7499 | roc auc 0.9154 | pr auc 0.8484 | elapsed 84.21s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1074 | val loss 0.2783 | acc 0.9071 | f1 0.7642 | prec 0.7696 | recall 0.7587 | roc auc 0.9216 | pr auc 0.8585 | elapsed 83.46s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0999 | val loss 0.2770 | acc 0.9069 | f1 0.7663 | prec 0.7638 | recall 0.7688 | roc auc 0.9264 | pr auc 0.8657 | elapsed 94.53s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0936 | val loss 0.2768 | acc 0.9090 | f1 0.7720 | prec 0.7677 | recall 0.7764 | roc auc 0.9294 | pr auc 0.8708 | elapsed 94.97s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0881 | val loss 0.2754 | acc 0.9114 | f1 0.7772 | prec 0.7759 | recall 0.7786 | roc auc 0.9316 | pr auc 0.8752 | elapsed 89.10s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0833 | val loss 0.2795 | acc 0.9114 | f1 0.7783 | prec 0.7727 | recall 0.7839 | roc auc 0.9334 | pr auc 0.8778 | elapsed 85.63s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0791 | val loss 0.2867 | acc 0.9114 | f1 0.7804 | prec 0.7678 | recall 0.7934 | roc auc 0.9346 | pr auc 0.8793 | elapsed 86.26s\n",
      "prc:  0.8793024527424613\n",
      "roc:  0.9346459271538425\n",
      "acc:  0.911375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 08:36:20,777] Trial 27 finished with value: 15.312275090347669 and parameters: {'identity_weight': 18, 'decay': 967}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 1.7345 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.43s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 1.1449 | val loss 0.4764 | acc 0.8251 | f1 0.3666 | prec 0.6511 | recall 0.2551 | roc auc 0.6687 | pr auc 0.4716 | elapsed 86.33s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.6535 | val loss 0.4047 | acc 0.8427 | f1 0.5220 | prec 0.6577 | recall 0.4328 | roc auc 0.7747 | pr auc 0.6043 | elapsed 89.27s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.4359 | val loss 0.3827 | acc 0.8551 | f1 0.6023 | prec 0.6615 | recall 0.5528 | roc auc 0.8179 | pr auc 0.6814 | elapsed 90.22s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2750 | val loss 0.3618 | acc 0.8659 | f1 0.6467 | prec 0.6775 | recall 0.6186 | roc auc 0.8471 | pr auc 0.7341 | elapsed 91.07s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2033 | val loss 0.3397 | acc 0.8745 | f1 0.6750 | prec 0.6943 | recall 0.6567 | roc auc 0.8680 | pr auc 0.7726 | elapsed 91.51s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1704 | val loss 0.3284 | acc 0.8801 | f1 0.6982 | prec 0.6976 | recall 0.6989 | roc auc 0.8833 | pr auc 0.7981 | elapsed 89.70s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1479 | val loss 0.3144 | acc 0.8872 | f1 0.7180 | prec 0.7123 | recall 0.7238 | roc auc 0.8952 | pr auc 0.8178 | elapsed 88.99s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1317 | val loss 0.3075 | acc 0.8904 | f1 0.7297 | prec 0.7145 | recall 0.7455 | roc auc 0.9048 | pr auc 0.8321 | elapsed 91.51s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1197 | val loss 0.2995 | acc 0.8949 | f1 0.7408 | prec 0.7252 | recall 0.7572 | roc auc 0.9119 | pr auc 0.8432 | elapsed 94.55s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1102 | val loss 0.2933 | acc 0.9002 | f1 0.7523 | prec 0.7417 | recall 0.7631 | roc auc 0.9175 | pr auc 0.8520 | elapsed 94.96s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1026 | val loss 0.2933 | acc 0.8992 | f1 0.7523 | prec 0.7345 | recall 0.7710 | roc auc 0.9221 | pr auc 0.8586 | elapsed 91.38s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0961 | val loss 0.2932 | acc 0.9001 | f1 0.7551 | prec 0.7353 | recall 0.7761 | roc auc 0.9250 | pr auc 0.8631 | elapsed 91.74s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0904 | val loss 0.2921 | acc 0.9037 | f1 0.7629 | prec 0.7458 | recall 0.7808 | roc auc 0.9274 | pr auc 0.8671 | elapsed 88.61s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0853 | val loss 0.2968 | acc 0.9045 | f1 0.7661 | prec 0.7453 | recall 0.7880 | roc auc 0.9292 | pr auc 0.8695 | elapsed 87.29s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0808 | val loss 0.3068 | acc 0.9011 | f1 0.7614 | prec 0.7305 | recall 0.7950 | roc auc 0.9306 | pr auc 0.8711 | elapsed 87.84s\n",
      "prc:  0.8710548481821604\n",
      "roc:  0.9305621955150342\n",
      "acc:  0.901125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 08:59:31,215] Trial 28 finished with value: 15.19504665491181 and parameters: {'identity_weight': 66, 'decay': 918}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 1.3422 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 30.71s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.9394 | val loss 0.4753 | acc 0.8275 | f1 0.3506 | prec 0.6930 | recall 0.2346 | roc auc 0.6660 | pr auc 0.4699 | elapsed 95.81s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5634 | val loss 0.4016 | acc 0.8436 | f1 0.5147 | prec 0.6699 | recall 0.4180 | roc auc 0.7758 | pr auc 0.6052 | elapsed 100.23s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3854 | val loss 0.3803 | acc 0.8581 | f1 0.6020 | prec 0.6789 | recall 0.5408 | roc auc 0.8183 | pr auc 0.6809 | elapsed 100.96s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2601 | val loss 0.3595 | acc 0.8691 | f1 0.6498 | prec 0.6927 | recall 0.6120 | roc auc 0.8468 | pr auc 0.7331 | elapsed 101.42s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2005 | val loss 0.3375 | acc 0.8774 | f1 0.6791 | prec 0.7067 | recall 0.6535 | roc auc 0.8678 | pr auc 0.7714 | elapsed 100.56s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1699 | val loss 0.3241 | acc 0.8822 | f1 0.6998 | prec 0.7082 | recall 0.6917 | roc auc 0.8833 | pr auc 0.7976 | elapsed 100.08s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1483 | val loss 0.3094 | acc 0.8898 | f1 0.7201 | prec 0.7256 | recall 0.7146 | roc auc 0.8956 | pr auc 0.8180 | elapsed 101.18s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1323 | val loss 0.3023 | acc 0.8929 | f1 0.7327 | prec 0.7260 | recall 0.7395 | roc auc 0.9055 | pr auc 0.8329 | elapsed 101.44s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1203 | val loss 0.2942 | acc 0.8972 | f1 0.7443 | prec 0.7352 | recall 0.7537 | roc auc 0.9129 | pr auc 0.8444 | elapsed 103.28s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1111 | val loss 0.2882 | acc 0.9006 | f1 0.7518 | prec 0.7447 | recall 0.7591 | roc auc 0.9187 | pr auc 0.8535 | elapsed 98.51s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1037 | val loss 0.2877 | acc 0.9006 | f1 0.7539 | prec 0.7412 | recall 0.7669 | roc auc 0.9234 | pr auc 0.8602 | elapsed 98.99s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0975 | val loss 0.2876 | acc 0.9015 | f1 0.7568 | prec 0.7419 | recall 0.7723 | roc auc 0.9264 | pr auc 0.8649 | elapsed 99.37s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0920 | val loss 0.2866 | acc 0.9038 | f1 0.7612 | prec 0.7496 | recall 0.7732 | roc auc 0.9288 | pr auc 0.8689 | elapsed 101.44s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0871 | val loss 0.2914 | acc 0.9054 | f1 0.7661 | prec 0.7517 | recall 0.7811 | roc auc 0.9306 | pr auc 0.8714 | elapsed 103.90s\n",
      "train epoch 15/15 | batch 2000/2000 | loss 0.0828 | elapsed 98.98s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 09:25:14,289] Trial 29 finished with value: 15.222964792273162 and parameters: {'identity_weight': 39, 'decay': 961}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 15/15 | batch 2001/2000 | loss 0.0828 | val loss 0.3009 | acc 0.9027 | f1 0.7632 | prec 0.7379 | recall 0.7902 | roc auc 0.9319 | pr auc 0.8729 | elapsed 102.01s\n",
      "prc:  0.8728954807583746\n",
      "roc:  0.9318870807815689\n",
      "acc:  0.9026875\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.2405 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 36.62s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.8752 | val loss 0.4755 | acc 0.8284 | f1 0.3450 | prec 0.7116 | recall 0.2277 | roc auc 0.6642 | pr auc 0.4685 | elapsed 102.10s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5307 | val loss 0.4010 | acc 0.8436 | f1 0.5094 | prec 0.6748 | recall 0.4091 | roc auc 0.7754 | pr auc 0.6042 | elapsed 103.66s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3691 | val loss 0.3783 | acc 0.8586 | f1 0.5994 | prec 0.6847 | recall 0.5329 | roc auc 0.8179 | pr auc 0.6804 | elapsed 104.32s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2590 | val loss 0.3590 | acc 0.8699 | f1 0.6490 | prec 0.6982 | recall 0.6063 | roc auc 0.8464 | pr auc 0.7316 | elapsed 107.13s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1975 | val loss 0.3362 | acc 0.8789 | f1 0.6809 | prec 0.7137 | recall 0.6510 | roc auc 0.8677 | pr auc 0.7707 | elapsed 107.44s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1675 | val loss 0.3216 | acc 0.8844 | f1 0.7027 | prec 0.7174 | recall 0.6885 | roc auc 0.8835 | pr auc 0.7976 | elapsed 107.70s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1462 | val loss 0.3061 | acc 0.8921 | f1 0.7238 | prec 0.7356 | recall 0.7124 | roc auc 0.8960 | pr auc 0.8187 | elapsed 107.99s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1301 | val loss 0.2983 | acc 0.8950 | f1 0.7354 | prec 0.7354 | recall 0.7354 | roc auc 0.9062 | pr auc 0.8340 | elapsed 109.05s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1180 | val loss 0.2900 | acc 0.8993 | f1 0.7472 | prec 0.7445 | recall 0.7499 | roc auc 0.9138 | pr auc 0.8460 | elapsed 112.82s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1086 | val loss 0.2842 | acc 0.9024 | f1 0.7552 | prec 0.7520 | recall 0.7584 | roc auc 0.9198 | pr auc 0.8555 | elapsed 109.50s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.1011 | val loss 0.2830 | acc 0.9020 | f1 0.7563 | prec 0.7465 | recall 0.7663 | roc auc 0.9245 | pr auc 0.8623 | elapsed 109.56s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0949 | val loss 0.2826 | acc 0.9041 | f1 0.7615 | prec 0.7519 | recall 0.7713 | roc auc 0.9276 | pr auc 0.8672 | elapsed 105.80s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0894 | val loss 0.2811 | acc 0.9070 | f1 0.7679 | prec 0.7606 | recall 0.7754 | roc auc 0.9300 | pr auc 0.8715 | elapsed 108.00s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0846 | val loss 0.2854 | acc 0.9076 | f1 0.7704 | prec 0.7602 | recall 0.7808 | roc auc 0.9318 | pr auc 0.8740 | elapsed 108.98s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0803 | val loss 0.2937 | acc 0.9073 | f1 0.7718 | prec 0.7541 | recall 0.7902 | roc auc 0.9331 | pr auc 0.8756 | elapsed 109.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 09:52:48,263] Trial 30 finished with value: 15.262068062157768 and parameters: {'identity_weight': 32, 'decay': 947}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prc:  0.8756276974530562\n",
      "roc:  0.9330901812712008\n",
      "acc:  0.90725\n",
      "train epoch 00/15 | batch 2001/2000 | loss 0.9355 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 31.99s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.6966 | val loss 0.4817 | acc 0.8306 | f1 0.3012 | prec 0.8307 | recall 0.1839 | roc auc 0.6459 | pr auc 0.4508 | elapsed 86.52s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4521 | val loss 0.4032 | acc 0.8438 | f1 0.4851 | prec 0.7014 | recall 0.3707 | roc auc 0.7692 | pr auc 0.5914 | elapsed 89.83s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3311 | val loss 0.3774 | acc 0.8607 | f1 0.5859 | prec 0.7142 | recall 0.4967 | roc auc 0.8111 | pr auc 0.6698 | elapsed 87.49s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2564 | val loss 0.3509 | acc 0.8748 | f1 0.6440 | prec 0.7390 | recall 0.5707 | roc auc 0.8407 | pr auc 0.7272 | elapsed 85.75s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2076 | val loss 0.3311 | acc 0.8835 | f1 0.6806 | prec 0.7463 | recall 0.6255 | roc auc 0.8632 | pr auc 0.7654 | elapsed 94.29s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1735 | val loss 0.3160 | acc 0.8905 | f1 0.7082 | prec 0.7515 | recall 0.6696 | roc auc 0.8813 | pr auc 0.7937 | elapsed 93.56s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1469 | val loss 0.3016 | acc 0.8972 | f1 0.7307 | prec 0.7614 | recall 0.7024 | roc auc 0.8965 | pr auc 0.8177 | elapsed 81.08s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1273 | val loss 0.2899 | acc 0.9016 | f1 0.7463 | prec 0.7637 | recall 0.7298 | roc auc 0.9078 | pr auc 0.8353 | elapsed 81.15s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1147 | val loss 0.2801 | acc 0.9069 | f1 0.7605 | prec 0.7767 | recall 0.7449 | roc auc 0.9160 | pr auc 0.8492 | elapsed 86.59s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1051 | val loss 0.2745 | acc 0.9114 | f1 0.7719 | prec 0.7895 | recall 0.7550 | roc auc 0.9221 | pr auc 0.8598 | elapsed 86.38s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0975 | val loss 0.2727 | acc 0.9123 | f1 0.7762 | prec 0.7857 | recall 0.7669 | roc auc 0.9270 | pr auc 0.8675 | elapsed 86.98s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0912 | val loss 0.2729 | acc 0.9136 | f1 0.7804 | prec 0.7870 | recall 0.7739 | roc auc 0.9301 | pr auc 0.8728 | elapsed 86.06s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0858 | val loss 0.2722 | acc 0.9174 | f1 0.7883 | prec 0.8017 | recall 0.7754 | roc auc 0.9322 | pr auc 0.8773 | elapsed 81.87s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0812 | val loss 0.2760 | acc 0.9179 | f1 0.7910 | prec 0.7991 | recall 0.7830 | roc auc 0.9339 | pr auc 0.8802 | elapsed 83.59s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0770 | val loss 0.2823 | acc 0.9177 | f1 0.7926 | prec 0.7933 | recall 0.7918 | roc auc 0.9352 | pr auc 0.8820 | elapsed 82.53s\n",
      "prc:  0.8820102410712192\n",
      "roc:  0.9352277386379333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 10:14:57,038] Trial 31 finished with value: 15.349218842539791 and parameters: {'identity_weight': 11, 'decay': 944}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.91775\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.0226 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 29.98s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7489 | val loss 0.4773 | acc 0.8313 | f1 0.3236 | prec 0.7907 | recall 0.2035 | roc auc 0.6559 | pr auc 0.4609 | elapsed 87.44s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4740 | val loss 0.4013 | acc 0.8438 | f1 0.4953 | prec 0.6903 | recall 0.3861 | roc auc 0.7727 | pr auc 0.5982 | elapsed 83.29s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3430 | val loss 0.3764 | acc 0.8607 | f1 0.5932 | prec 0.7053 | recall 0.5118 | roc auc 0.8150 | pr auc 0.6758 | elapsed 86.40s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2599 | val loss 0.3523 | acc 0.8734 | f1 0.6479 | prec 0.7232 | recall 0.5868 | roc auc 0.8446 | pr auc 0.7312 | elapsed 87.70s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2023 | val loss 0.3367 | acc 0.8812 | f1 0.6831 | prec 0.7256 | recall 0.6454 | roc auc 0.8667 | pr auc 0.7673 | elapsed 86.36s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1654 | val loss 0.3187 | acc 0.8871 | f1 0.7061 | prec 0.7305 | recall 0.6831 | roc auc 0.8834 | pr auc 0.7960 | elapsed 85.78s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1443 | val loss 0.3017 | acc 0.8956 | f1 0.7282 | prec 0.7529 | recall 0.7052 | roc auc 0.8967 | pr auc 0.8189 | elapsed 85.82s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1283 | val loss 0.2921 | acc 0.8986 | f1 0.7406 | prec 0.7522 | recall 0.7294 | roc auc 0.9074 | pr auc 0.8354 | elapsed 86.28s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1161 | val loss 0.2831 | acc 0.9042 | f1 0.7564 | prec 0.7639 | recall 0.7490 | roc auc 0.9155 | pr auc 0.8486 | elapsed 83.39s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1065 | val loss 0.2775 | acc 0.9082 | f1 0.7662 | prec 0.7745 | recall 0.7581 | roc auc 0.9217 | pr auc 0.8588 | elapsed 87.53s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0990 | val loss 0.2761 | acc 0.9083 | f1 0.7689 | prec 0.7686 | recall 0.7691 | roc auc 0.9265 | pr auc 0.8661 | elapsed 81.82s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0926 | val loss 0.2759 | acc 0.9099 | f1 0.7736 | prec 0.7712 | recall 0.7761 | roc auc 0.9296 | pr auc 0.8713 | elapsed 87.20s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0872 | val loss 0.2745 | acc 0.9133 | f1 0.7809 | prec 0.7827 | recall 0.7792 | roc auc 0.9318 | pr auc 0.8757 | elapsed 87.07s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0824 | val loss 0.2786 | acc 0.9128 | f1 0.7808 | prec 0.7792 | recall 0.7824 | roc auc 0.9335 | pr auc 0.8784 | elapsed 83.01s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0781 | val loss 0.2857 | acc 0.9133 | f1 0.7841 | prec 0.7751 | recall 0.7934 | roc auc 0.9348 | pr auc 0.8801 | elapsed 83.10s\n",
      "prc:  0.8800500684052985\n",
      "roc:  0.9347933753894798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 10:36:52,127] Trial 32 finished with value: 15.322573436389863 and parameters: {'identity_weight': 17, 'decay': 954}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9133125\n",
      "train epoch 00/15 | batch 2001/2000 | loss 0.9355 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.49s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.6957 | val loss 0.4818 | acc 0.8306 | f1 0.3005 | prec 0.8326 | recall 0.1833 | roc auc 0.6456 | pr auc 0.4506 | elapsed 83.79s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4512 | val loss 0.4033 | acc 0.8437 | f1 0.4842 | prec 0.7013 | recall 0.3698 | roc auc 0.7690 | pr auc 0.5912 | elapsed 89.75s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3303 | val loss 0.3775 | acc 0.8605 | f1 0.5847 | prec 0.7144 | recall 0.4948 | roc auc 0.8109 | pr auc 0.6695 | elapsed 91.08s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2557 | val loss 0.3509 | acc 0.8750 | f1 0.6439 | prec 0.7407 | recall 0.5694 | roc auc 0.8405 | pr auc 0.7270 | elapsed 90.75s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2072 | val loss 0.3310 | acc 0.8838 | f1 0.6810 | prec 0.7481 | recall 0.6249 | roc auc 0.8629 | pr auc 0.7651 | elapsed 91.15s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1734 | val loss 0.3157 | acc 0.8909 | f1 0.7087 | prec 0.7535 | recall 0.6690 | roc auc 0.8810 | pr auc 0.7935 | elapsed 87.09s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1474 | val loss 0.3006 | acc 0.8976 | f1 0.7306 | prec 0.7639 | recall 0.7002 | roc auc 0.8962 | pr auc 0.8176 | elapsed 91.13s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1273 | val loss 0.2901 | acc 0.9014 | f1 0.7460 | prec 0.7633 | recall 0.7294 | roc auc 0.9078 | pr auc 0.8352 | elapsed 89.79s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1144 | val loss 0.2801 | acc 0.9071 | f1 0.7612 | prec 0.7772 | recall 0.7458 | roc auc 0.9160 | pr auc 0.8492 | elapsed 89.31s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1048 | val loss 0.2745 | acc 0.9117 | f1 0.7723 | prec 0.7914 | recall 0.7540 | roc auc 0.9221 | pr auc 0.8598 | elapsed 89.94s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0971 | val loss 0.2726 | acc 0.9123 | f1 0.7761 | prec 0.7859 | recall 0.7666 | roc auc 0.9270 | pr auc 0.8675 | elapsed 88.97s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0908 | val loss 0.2729 | acc 0.9138 | f1 0.7807 | prec 0.7884 | recall 0.7732 | roc auc 0.9300 | pr auc 0.8729 | elapsed 90.54s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0855 | val loss 0.2722 | acc 0.9179 | f1 0.7895 | prec 0.8040 | recall 0.7754 | roc auc 0.9322 | pr auc 0.8774 | elapsed 90.01s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0808 | val loss 0.2761 | acc 0.9184 | f1 0.7918 | prec 0.8017 | recall 0.7820 | roc auc 0.9338 | pr auc 0.8802 | elapsed 91.45s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0766 | val loss 0.2823 | acc 0.9177 | f1 0.7924 | prec 0.7932 | recall 0.7915 | roc auc 0.9352 | pr auc 0.8821 | elapsed 92.74s\n",
      "prc:  0.8820718246672112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 10:59:54,895] Trial 33 finished with value: 15.349443440644574 and parameters: {'identity_weight': 11, 'decay': 935}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc:  0.9351729489954106\n",
      "acc:  0.9176875\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.1388 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 33.47s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.8130 | val loss 0.4767 | acc 0.8291 | f1 0.3364 | prec 0.7333 | recall 0.2183 | roc auc 0.6604 | pr auc 0.4653 | elapsed 87.95s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5004 | val loss 0.4007 | acc 0.8439 | f1 0.5040 | prec 0.6819 | recall 0.3997 | roc auc 0.7745 | pr auc 0.6022 | elapsed 93.05s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3540 | val loss 0.3765 | acc 0.8599 | f1 0.5969 | prec 0.6959 | recall 0.5225 | roc auc 0.8169 | pr auc 0.6791 | elapsed 92.66s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2591 | val loss 0.3552 | acc 0.8728 | f1 0.6517 | prec 0.7132 | recall 0.6000 | roc auc 0.8460 | pr auc 0.7321 | elapsed 92.56s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1963 | val loss 0.3352 | acc 0.8796 | f1 0.6810 | prec 0.7181 | recall 0.6476 | roc auc 0.8674 | pr auc 0.7696 | elapsed 91.52s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1653 | val loss 0.3194 | acc 0.8866 | f1 0.7054 | prec 0.7277 | recall 0.6844 | roc auc 0.8835 | pr auc 0.7972 | elapsed 92.28s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1442 | val loss 0.3031 | acc 0.8949 | f1 0.7284 | prec 0.7473 | recall 0.7106 | roc auc 0.8965 | pr auc 0.8191 | elapsed 94.33s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1282 | val loss 0.2944 | acc 0.8964 | f1 0.7367 | prec 0.7430 | recall 0.7304 | roc auc 0.9069 | pr auc 0.8351 | elapsed 95.04s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1160 | val loss 0.2857 | acc 0.9024 | f1 0.7532 | prec 0.7558 | recall 0.7506 | roc auc 0.9147 | pr auc 0.8476 | elapsed 93.56s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1066 | val loss 0.2798 | acc 0.9058 | f1 0.7616 | prec 0.7651 | recall 0.7581 | roc auc 0.9209 | pr auc 0.8575 | elapsed 93.61s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0990 | val loss 0.2785 | acc 0.9065 | f1 0.7649 | prec 0.7632 | recall 0.7666 | roc auc 0.9256 | pr auc 0.8646 | elapsed 91.48s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0926 | val loss 0.2783 | acc 0.9076 | f1 0.7684 | prec 0.7640 | recall 0.7729 | roc auc 0.9287 | pr auc 0.8697 | elapsed 94.08s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0871 | val loss 0.2769 | acc 0.9106 | f1 0.7750 | prec 0.7739 | recall 0.7761 | roc auc 0.9310 | pr auc 0.8740 | elapsed 92.97s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0823 | val loss 0.2808 | acc 0.9108 | f1 0.7768 | prec 0.7716 | recall 0.7820 | roc auc 0.9328 | pr auc 0.8767 | elapsed 94.42s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0780 | val loss 0.2881 | acc 0.9104 | f1 0.7775 | prec 0.7663 | recall 0.7890 | roc auc 0.9340 | pr auc 0.8782 | elapsed 93.12s\n",
      "prc:  0.8782200009278602\n",
      "roc:  0.9340308391275651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 11:23:44,233] Trial 34 finished with value: 15.296760044043994 and parameters: {'identity_weight': 25, 'decay': 932}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.910375\n",
      "train epoch 00/15 | batch 2001/2000 | loss 0.9209 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 32.84s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.6861 | val loss 0.4830 | acc 0.8306 | f1 0.2942 | prec 0.8483 | recall 0.1780 | roc auc 0.6428 | pr auc 0.4475 | elapsed 90.14s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4469 | val loss 0.4039 | acc 0.8434 | f1 0.4799 | prec 0.7036 | recall 0.3641 | roc auc 0.7680 | pr auc 0.5892 | elapsed 94.16s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3275 | val loss 0.3781 | acc 0.8597 | f1 0.5808 | prec 0.7133 | recall 0.4898 | roc auc 0.8096 | pr auc 0.6676 | elapsed 93.20s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2540 | val loss 0.3514 | acc 0.8752 | f1 0.6426 | prec 0.7447 | recall 0.5650 | roc auc 0.8390 | pr auc 0.7252 | elapsed 91.97s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2066 | val loss 0.3313 | acc 0.8846 | f1 0.6806 | prec 0.7551 | recall 0.6195 | roc auc 0.8612 | pr auc 0.7632 | elapsed 87.40s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1742 | val loss 0.3152 | acc 0.8910 | f1 0.7068 | prec 0.7580 | recall 0.6620 | roc auc 0.8793 | pr auc 0.7916 | elapsed 86.48s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1496 | val loss 0.2987 | acc 0.8993 | f1 0.7316 | prec 0.7765 | recall 0.6917 | roc auc 0.8946 | pr auc 0.8161 | elapsed 85.65s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1300 | val loss 0.2894 | acc 0.9018 | f1 0.7451 | prec 0.7680 | recall 0.7235 | roc auc 0.9072 | pr auc 0.8345 | elapsed 85.41s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1145 | val loss 0.2810 | acc 0.9081 | f1 0.7627 | prec 0.7817 | recall 0.7446 | roc auc 0.9160 | pr auc 0.8489 | elapsed 88.97s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1042 | val loss 0.2749 | acc 0.9129 | f1 0.7744 | prec 0.7965 | recall 0.7534 | roc auc 0.9221 | pr auc 0.8597 | elapsed 87.55s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0966 | val loss 0.2727 | acc 0.9129 | f1 0.7771 | prec 0.7899 | recall 0.7647 | roc auc 0.9269 | pr auc 0.8674 | elapsed 87.37s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0902 | val loss 0.2730 | acc 0.9144 | f1 0.7818 | prec 0.7915 | recall 0.7723 | roc auc 0.9299 | pr auc 0.8728 | elapsed 87.60s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0849 | val loss 0.2725 | acc 0.9181 | f1 0.7896 | prec 0.8050 | recall 0.7748 | roc auc 0.9320 | pr auc 0.8774 | elapsed 87.98s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0803 | val loss 0.2763 | acc 0.9188 | f1 0.7924 | prec 0.8043 | recall 0.7808 | roc auc 0.9336 | pr auc 0.8803 | elapsed 88.16s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0761 | val loss 0.2824 | acc 0.9186 | f1 0.7943 | prec 0.7964 | recall 0.7921 | roc auc 0.9350 | pr auc 0.8822 | elapsed 87.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 11:46:29,826] Trial 35 finished with value: 15.350145086814234 and parameters: {'identity_weight': 10, 'decay': 921}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prc:  0.8821588278208072\n",
      "roc:  0.9349990514343601\n",
      "acc:  0.9185625\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.0081 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 30.77s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7340 | val loss 0.4782 | acc 0.8311 | f1 0.3183 | prec 0.7987 | recall 0.1987 | roc auc 0.6537 | pr auc 0.4588 | elapsed 86.28s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4645 | val loss 0.4017 | acc 0.8438 | f1 0.4920 | prec 0.6938 | recall 0.3811 | roc auc 0.7718 | pr auc 0.5965 | elapsed 84.75s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3361 | val loss 0.3763 | acc 0.8602 | f1 0.5890 | prec 0.7073 | recall 0.5046 | roc auc 0.8138 | pr auc 0.6742 | elapsed 85.07s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2564 | val loss 0.3509 | acc 0.8742 | f1 0.6473 | prec 0.7299 | recall 0.5814 | roc auc 0.8433 | pr auc 0.7304 | elapsed 86.85s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.2038 | val loss 0.3326 | acc 0.8831 | f1 0.6837 | prec 0.7380 | recall 0.6369 | roc auc 0.8656 | pr auc 0.7677 | elapsed 89.66s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1667 | val loss 0.3197 | acc 0.8868 | f1 0.7033 | prec 0.7324 | recall 0.6765 | roc auc 0.8831 | pr auc 0.7951 | elapsed 89.63s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1423 | val loss 0.3012 | acc 0.8965 | f1 0.7298 | prec 0.7572 | recall 0.7043 | roc auc 0.8968 | pr auc 0.8186 | elapsed 90.84s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1262 | val loss 0.2907 | acc 0.9008 | f1 0.7446 | prec 0.7608 | recall 0.7291 | roc auc 0.9076 | pr auc 0.8355 | elapsed 92.05s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1139 | val loss 0.2815 | acc 0.9058 | f1 0.7588 | prec 0.7709 | recall 0.7471 | roc auc 0.9157 | pr auc 0.8490 | elapsed 89.30s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1044 | val loss 0.2761 | acc 0.9097 | f1 0.7684 | prec 0.7828 | recall 0.7546 | roc auc 0.9218 | pr auc 0.8594 | elapsed 87.88s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0968 | val loss 0.2743 | acc 0.9109 | f1 0.7737 | prec 0.7797 | recall 0.7679 | roc auc 0.9267 | pr auc 0.8669 | elapsed 87.01s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0904 | val loss 0.2744 | acc 0.9131 | f1 0.7795 | prec 0.7852 | recall 0.7739 | roc auc 0.9297 | pr auc 0.8722 | elapsed 85.88s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0850 | val loss 0.2736 | acc 0.9164 | f1 0.7865 | prec 0.7970 | recall 0.7764 | roc auc 0.9319 | pr auc 0.8766 | elapsed 83.67s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0803 | val loss 0.2775 | acc 0.9166 | f1 0.7883 | prec 0.7937 | recall 0.7830 | roc auc 0.9336 | pr auc 0.8795 | elapsed 83.21s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0761 | val loss 0.2839 | acc 0.9166 | f1 0.7898 | prec 0.7897 | recall 0.7899 | roc auc 0.9348 | pr auc 0.8813 | elapsed 84.37s\n",
      "prc:  0.8812937853272251\n",
      "roc:  0.9348434129944284\n",
      "acc:  0.9165625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 12:08:50,156] Trial 36 finished with value: 15.338560831238821 and parameters: {'identity_weight': 16, 'decay': 910}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 00/15 | batch 2001/2000 | loss 1.1098 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 30.65s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.7943 | val loss 0.4774 | acc 0.8294 | f1 0.3338 | prec 0.7411 | recall 0.2154 | roc auc 0.6588 | pr auc 0.4639 | elapsed 84.36s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.4909 | val loss 0.4008 | acc 0.8438 | f1 0.5008 | prec 0.6841 | recall 0.3950 | roc auc 0.7739 | pr auc 0.6012 | elapsed 85.87s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3489 | val loss 0.3761 | acc 0.8613 | f1 0.5988 | prec 0.7029 | recall 0.5216 | roc auc 0.8163 | pr auc 0.6783 | elapsed 96.50s\n",
      "train epoch 04/15 | batch 2001/2000 | loss 0.2584 | val loss 0.3536 | acc 0.8731 | f1 0.6499 | prec 0.7183 | recall 0.5934 | roc auc 0.8455 | pr auc 0.7322 | elapsed 99.11s\n",
      "train epoch 05/15 | batch 2001/2000 | loss 0.1971 | val loss 0.3354 | acc 0.8803 | f1 0.6822 | prec 0.7211 | recall 0.6472 | roc auc 0.8671 | pr auc 0.7688 | elapsed 101.82s\n",
      "train epoch 06/15 | batch 2001/2000 | loss 0.1644 | val loss 0.3189 | acc 0.8870 | f1 0.7057 | prec 0.7302 | recall 0.6828 | roc auc 0.8834 | pr auc 0.7967 | elapsed 101.74s\n",
      "train epoch 07/15 | batch 2001/2000 | loss 0.1434 | val loss 0.3024 | acc 0.8950 | f1 0.7279 | prec 0.7492 | recall 0.7077 | roc auc 0.8964 | pr auc 0.8190 | elapsed 107.33s\n",
      "train epoch 08/15 | batch 2001/2000 | loss 0.1274 | val loss 0.2933 | acc 0.8969 | f1 0.7372 | prec 0.7457 | recall 0.7288 | roc auc 0.9070 | pr auc 0.8352 | elapsed 106.55s\n",
      "train epoch 09/15 | batch 2001/2000 | loss 0.1152 | val loss 0.2844 | acc 0.9029 | f1 0.7538 | prec 0.7584 | recall 0.7493 | roc auc 0.9149 | pr auc 0.8480 | elapsed 102.59s\n",
      "train epoch 10/15 | batch 2001/2000 | loss 0.1057 | val loss 0.2788 | acc 0.9070 | f1 0.7637 | prec 0.7703 | recall 0.7572 | roc auc 0.9211 | pr auc 0.8580 | elapsed 101.33s\n",
      "train epoch 11/15 | batch 2001/2000 | loss 0.0981 | val loss 0.2773 | acc 0.9074 | f1 0.7668 | prec 0.7667 | recall 0.7669 | roc auc 0.9258 | pr auc 0.8652 | elapsed 105.82s\n",
      "train epoch 12/15 | batch 2001/2000 | loss 0.0917 | val loss 0.2771 | acc 0.9091 | f1 0.7715 | prec 0.7693 | recall 0.7739 | roc auc 0.9289 | pr auc 0.8703 | elapsed 102.75s\n",
      "train epoch 13/15 | batch 2001/2000 | loss 0.0863 | val loss 0.2757 | acc 0.9128 | f1 0.7798 | prec 0.7816 | recall 0.7780 | roc auc 0.9312 | pr auc 0.8747 | elapsed 104.34s\n",
      "train epoch 14/15 | batch 2001/2000 | loss 0.0815 | val loss 0.2797 | acc 0.9122 | f1 0.7794 | prec 0.7771 | recall 0.7817 | roc auc 0.9329 | pr auc 0.8774 | elapsed 105.73s\n",
      "train epoch 15/15 | batch 2001/2000 | loss 0.0772 | val loss 0.2869 | acc 0.9119 | f1 0.7806 | prec 0.7719 | recall 0.7896 | roc auc 0.9342 | pr auc 0.8791 | elapsed 104.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-30 12:34:34,999] Trial 37 finished with value: 15.307544241035316 and parameters: {'identity_weight': 23, 'decay': 921}. Best is trial 21 with value: 15.352123754165543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prc:  0.8790478592580189\n",
      "roc:  0.9341880247425212\n",
      "acc:  0.9119375\n",
      "train epoch 00/15 | batch 2001/2000 | loss 1.3567 | val loss 0.7750 | acc 0.1984 | f1 0.3312 | prec 0.1984 | recall 1.0000 | roc auc 0.5216 | pr auc 0.2296 | elapsed 40.56s\n",
      "train epoch 01/15 | batch 2001/2000 | loss 0.9301 | val loss 0.4753 | acc 0.8277 | f1 0.3499 | prec 0.6961 | recall 0.2337 | roc auc 0.6659 | pr auc 0.4699 | elapsed 108.09s\n",
      "train epoch 02/15 | batch 2001/2000 | loss 0.5508 | val loss 0.4013 | acc 0.8436 | f1 0.5131 | prec 0.6709 | recall 0.4154 | roc auc 0.7757 | pr auc 0.6050 | elapsed 109.45s\n",
      "train epoch 03/15 | batch 2001/2000 | loss 0.3760 | val loss 0.3791 | acc 0.8580 | f1 0.6000 | prec 0.6802 | recall 0.5367 | roc auc 0.8181 | pr auc 0.6811 | elapsed 104.97s\n",
      "train epoch 04/15 | batch 0536/2000 | loss 0.2863 | elapsed 27.40s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-07-30 12:41:06,460] Trial 38 failed with parameters: {'identity_weight': 40, 'decay': 911} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/janek/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_4499/4089852266.py\", line 16, in objective\n",
      "    y, Y = train_mod(data_tr, data_vl, trained_reasoner, encoders, epoch_count=15,\n",
      "  File \"/home/janek/reasonable-embeddings/src/reasoner_mod.py\", line 317, in train_mod\n",
      "    loss, yb, Yb = eval_batch_mod(reasoner, encoders, X_tr, y_tr, idx_tr, idxs, backward=epoch_idx > 0,\n",
      "  File \"/home/janek/reasonable-embeddings/src/reasoner_mod.py\", line 281, in eval_batch_mod\n",
      "    loss.backward()\n",
      "  File \"/home/janek/miniconda3/envs/reasoner/lib/python3.9/site-packages/torch/_tensor.py\", line 307, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/janek/miniconda3/envs/reasoner/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 154, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n",
      "[W 2024-07-30 12:41:06,462] Trial 38 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(rec, prec)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m roc_auc_score(y,Y)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m \u001b[38;5;241m+\u001b[39m accuracy_score(y,K)\n\u001b[1;32m     28\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Wywietl najlepsze hiperparametry oraz warto dokadnoci\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNajlepsze hiperparametry:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     14\u001b[0m id_weight\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     15\u001b[0m decay\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m---> 16\u001b[0m y, Y \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_vl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_reasoner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midentities_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midentitity_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m prec, rec, _ \u001b[38;5;241m=\u001b[39m precision_recall_curve(y, Y)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprc: \u001b[39m\u001b[38;5;124m'\u001b[39m, auc(rec, prec))\n",
      "File \u001b[0;32m~/reasonable-embeddings/src/reasoner_mod.py:317\u001b[0m, in \u001b[0;36mtrain_mod\u001b[0;34m(data_tr, data_vl, reasoner, encoders, epoch_count, batch_size, logger, validate, optimizer, lr_reasoner, lr_encoder, freeze_reasoner, run_name, identities_weight, identitity_weight_decay, one_onto)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m optim \u001b[38;5;129;01min\u001b[39;00m optimizers:\n\u001b[1;32m    316\u001b[0m \toptim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 317\u001b[0m loss, yb, Yb \u001b[38;5;241m=\u001b[39m eval_batch_mod(reasoner, encoders, X_tr, y_tr, idx_tr, idxs, backward\u001b[38;5;241m=\u001b[39mepoch_idx \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    318\u001b[0m \tidentities_weight\u001b[38;5;241m=\u001b[39midentities_weight)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m optim \u001b[38;5;129;01min\u001b[39;00m optimizers:\n\u001b[1;32m    320\u001b[0m \toptim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/reasonable-embeddings/src/reasoner_mod.py:281\u001b[0m, in \u001b[0;36meval_batch_mod\u001b[0;34m(reasoner, encoders, X, y, onto_idx, indices, backward, detach, identities_weight, frozen, one_onto)\u001b[0m\n\u001b[1;32m    278\u001b[0m loss \u001b[38;5;241m=\u001b[39m main_loss \u001b[38;5;241m+\u001b[39m identity_loss\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backward:\n\u001b[0;32m--> 281\u001b[0m \tloss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    283\u001b[0m Y_ \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39msigmoid(Y_)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detach:\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoner/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def objective(trial):\n",
    "    T.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    trained_reasoner = ModifiedReasonerHead(emb_size=emb_size, hidden_size=hidden_size)\n",
    "    encoders = [ModifiedEmbeddingLayer.from_onto(onto, emb_size=emb_size) for onto in train_onto]\n",
    "\n",
    "    id_weight = trial.suggest_int('identity_weight', 10, 100)\n",
    "    decay= trial.suggest_int('decay',900, 999)\n",
    "\n",
    "    id_weight/=1000\n",
    "    decay/=1000\n",
    "    y, Y = train_mod(data_tr, data_vl, trained_reasoner, encoders, epoch_count=15,\n",
    "                            batch_size=batch_size, identities_weight=id_weight, identitity_weight_decay=decay)\n",
    "    \n",
    "    prec, rec, _ = precision_recall_curve(y, Y)\n",
    "    \n",
    "    print('prc: ', auc(rec, prec))\n",
    "    print('roc: ', roc_auc_score(y,Y))\n",
    "    K = np.array(Y) > 0.5\n",
    "    print('acc: ',accuracy_score(y,K))\n",
    "\n",
    "    return auc(rec, prec)*10 + roc_auc_score(y,Y)*6 + accuracy_score(y,K)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Wywietl najlepsze hiperparametry oraz warto dokadnoci\n",
    "print('Najlepsze hiperparametry:')\n",
    "print(study.best_params)\n",
    "print('Warto redniej dokadnoci dla najlepszych hiperparametrw:')\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7aa831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T12:39:07.917372Z",
     "start_time": "2022-04-30T12:39:07.917335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained reasoner\n",
      "train epoch 00/10 | batch 849/848 | loss 0.7694 | val loss 0.7728 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.4990 | pr auc 0.2375 | elapsed 7.20s\n",
      "train epoch 01/10 | batch 849/848 | loss 0.7689 | val loss 0.7724 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5104 | pr auc 0.2452 | elapsed 12.84s\n",
      "train epoch 02/10 | batch 849/848 | loss 0.7677 | val loss 0.7720 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5223 | pr auc 0.2537 | elapsed 12.80s\n",
      "train epoch 03/10 | batch 849/848 | loss 0.7664 | val loss 0.7715 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5342 | pr auc 0.2620 | elapsed 12.35s\n",
      "train epoch 04/10 | batch 849/848 | loss 0.7651 | val loss 0.7711 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5454 | pr auc 0.2704 | elapsed 12.64s\n",
      "train epoch 05/10 | batch 849/848 | loss 0.7638 | val loss 0.7706 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5556 | pr auc 0.2780 | elapsed 13.00s\n",
      "train epoch 06/10 | batch 849/848 | loss 0.7625 | val loss 0.7702 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5644 | pr auc 0.2849 | elapsed 13.07s\n",
      "train epoch 07/10 | batch 849/848 | loss 0.7612 | val loss 0.7698 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5722 | pr auc 0.2908 | elapsed 12.61s\n",
      "train epoch 08/10 | batch 849/848 | loss 0.7599 | val loss 0.7693 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5788 | pr auc 0.2960 | elapsed 12.91s\n",
      "train epoch 09/10 | batch 849/848 | loss 0.7586 | val loss 0.7689 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5845 | pr auc 0.3009 | elapsed 12.34s\n",
      "train epoch 10/10 | batch 849/848 | loss 0.7572 | val loss 0.7685 | acc 0.2077 | f1 0.3440 | prec 0.2077 | recall 1.0000 | roc auc 0.5892 | pr auc 0.3049 | elapsed 12.81s\n"
     ]
    }
   ],
   "source": [
    "## --- TESTING\n",
    "trained_test_encoders = {}\n",
    "T.manual_seed(seed)\n",
    "test_logger = TrainingLogger(validate=True, metrics=batch_stats)\n",
    "\n",
    "for reasoner_name, reasoner in [('trained reasoner', trained_reasoner)]:\n",
    "    print(reasoner_name)\n",
    "    T.manual_seed(seed)\n",
    "    trained_test_encoders[reasoner_name] = test_encoders = [EmbeddingLayer.from_onto(onto, emb_size=emb_size) for onto in test_onto]\n",
    "    train_mod(data_te_tr, data_te_vl, reasoner, test_encoders, epoch_count=test_epoch_count, batch_size=batch_size, run_name=reasoner_name, freeze_reasoner=True, logger=test_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with T.no_grad():\n",
    "    # idx_te, X_te, y_te = data_te\n",
    "    _, _, Y_te_good = eval_batch(trained_reasoner, trained_test_encoders['trained reasoner'], X_te_te, y_te_te, idx_te_te)\n",
    "    # _, _, Y_te_rand = eval_batch(random_reasoner, trained_test_encoders['random reasoner'], X_te, y_te, idx_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb2c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T12:20:39.824396Z",
     "start_time": "2022-04-30T12:20:39.824337Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local/out/exp/20240716T183807\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(base)\n\u001b[1;32m      5\u001b[0m T\u001b[38;5;241m.\u001b[39msave(trained_reasoner\u001b[38;5;241m.\u001b[39mstate_dict(), base\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/reasoner.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m df_tr \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtrain_logger\u001b[49m\u001b[38;5;241m.\u001b[39mhistory_tr)\n\u001b[1;32m      7\u001b[0m df_vl \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(train_logger\u001b[38;5;241m.\u001b[39mhistory_vl)\n\u001b[1;32m      8\u001b[0m df_tr\u001b[38;5;241m.\u001b[39mto_csv(base\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_logger' is not defined"
     ]
    }
   ],
   "source": [
    "base = 'local/out/exp/' + ts\n",
    "mkdirp(base)\n",
    "print(base)\n",
    "\n",
    "T.save(trained_reasoner.state_dict(), base+'/reasoner.pt')\n",
    "df_tr = pd.DataFrame(train_logger.history_tr)\n",
    "df_vl = pd.DataFrame(train_logger.history_vl)\n",
    "df_tr.to_csv(base+'/train.csv', index=False)\n",
    "df_vl.to_csv(base+'/valid.csv', index=False)\n",
    "plot_train_history(df_tr, df_vl, save=base+'/train.png')\n",
    "\n",
    "test_history_by_onto = pd.DataFrame(test_logger.history_vl_by_onto)\n",
    "test_history = pd.DataFrame(test_logger.history_vl)\n",
    "test_results = pd.DataFrame(dict(idx_te=idx_te_te, y_te=y_te_te, Y_te_good=Y_te_good))\n",
    "test_history.to_csv(base+'/test.csv', index=False)\n",
    "test_history_by_onto.to_csv(base+'/test-grouped.csv', index=False)\n",
    "test_results.to_csv(base+'/test-results.csv', index=False)\n",
    "plot_test_history(test_history, test_history_by_onto)\n",
    "print(report(test_onto, y_te_te, np.array(Y_te_good), idx_te_te))\n",
    "# print(report(test_onto, y_te, np.array(Y_te_rand), idx_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec65fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e5a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0853,  0.0049,  0.0044,  0.1040, -0.2791, -0.0971, -0.0545, -0.2373,\n",
      "         0.0291, -0.1781], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0283, -0.1301,  0.1543, -0.1816,  0.1470, -0.1504, -0.1508, -0.1428,\n",
      "         0.1558,  0.1439], grad_fn=<AddBackward0>)\n",
      "0.14532663188874723\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input = encoder.concepts[ int(np.round( random.random() * encoder.n_concepts , 0) - 1) ]\n",
    "    losses.append( F.l1_loss(input, trained_reasoner.and_nn(im(input, input))).item() )\n",
    "\n",
    "\n",
    "print(input)\n",
    "print(trained_reasoner.and_nn(im( input, input)))\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8487,  0.3154, -0.0030, -0.4652,  0.9116, -0.0422,  0.2849,  0.1790,\n",
      "        -0.4642, -0.3235], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.5006,  0.4196, -0.2333, -0.1082,  0.1215,  0.4181,  0.3491,  0.4251,\n",
      "        -0.4716, -0.1767], grad_fn=<AddBackward0>)\n",
      "0.27251186221838\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input = encoder.concepts[ int(np.round( random.random() * encoder.n_concepts , 0) - 1) ]\n",
    "    losses.append(F.l1_loss(trained_reasoner.and_nn(im(trained_reasoner.bot_concept[0], input)), trained_reasoner.bot_concept[0]).item())\n",
    "print(trained_reasoner.bot_concept[0])\n",
    "print(trained_reasoner.and_nn(im(trained_reasoner.bot_concept[0], input)))\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0393, -0.1274, -0.2614, -0.1177, -0.0585, -0.0664,  0.1144, -0.2802,\n",
      "         0.1001,  0.0221], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.2182, -0.3193,  0.2273, -0.1661,  0.1478, -0.1756, -0.1602, -0.2823,\n",
      "         0.2452,  0.2916], grad_fn=<AddBackward0>)\n",
      "0.1793355718255043\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input = encoder.concepts[ int(np.round( random.random() * encoder.n_concepts , 0) - 1) ]\n",
    "    losses.append(F.l1_loss(trained_reasoner.and_nn(im(trained_reasoner.top_concept[0], input)), input).item())\n",
    "\n",
    "print(input)\n",
    "print(trained_reasoner.and_nn(im(trained_reasoner.top_concept[0], input)))\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5653f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8487,  0.3154, -0.0030, -0.4652,  0.9116, -0.0422,  0.2849,  0.1790,\n",
      "        -0.4642, -0.3235], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0291, -0.0860,  0.1372, -0.2300,  0.1739, -0.1169, -0.1536, -0.1260,\n",
      "         0.1137,  0.0972], grad_fn=<AddBackward0>)\n",
      "0.36536308377981186\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input = encoder.concepts[ int(np.round( random.random() * encoder.n_concepts , 0) - 1) ]\n",
    "    output = trained_reasoner.and_nn(im(trained_reasoner.not_nn(input), input))\n",
    "    losses.append(F.l1_loss(trained_reasoner.bot_concept[0], output).item())\n",
    "\n",
    "print(trained_reasoner.bot_concept[0])\n",
    "print(output)\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f65ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8487,  0.3154, -0.0030, -0.4652,  0.9116, -0.0422,  0.2849,  0.1790,\n",
      "        -0.4642, -0.3235], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.8487,  0.3152, -0.0028, -0.4649,  0.9116, -0.0422,  0.2849,  0.1790,\n",
      "        -0.4640, -0.3235], grad_fn=<SqueezeBackward3>)\n",
      "tensor(9.1464e-05, grad_fn=<L1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(trained_reasoner.bot_concept[0])\n",
    "output = trained_reasoner.not_nn(trained_reasoner.top_concept[0])\n",
    "print(output)\n",
    "print(F.l1_loss(trained_reasoner.bot_concept[0], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d1cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0286, -0.2194,  0.0205,  0.4425,  0.1463,  0.3542,  1.5009,  0.0721,\n",
      "        -0.2669,  0.2835], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0288, -0.2195,  0.0202,  0.4425,  0.1462,  0.3544,  1.5013,  0.0722,\n",
      "        -0.2671,  0.2835], grad_fn=<SqueezeBackward3>)\n",
      "tensor(0.0001, grad_fn=<L1LossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(trained_reasoner.top_concept[0])\n",
    "output = trained_reasoner.not_nn(trained_reasoner.bot_concept[0])\n",
    "print(output)\n",
    "print(F.l1_loss(trained_reasoner.top_concept[0], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79985d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1326, -0.0631,  0.0128, -0.1697,  0.1839,  0.0128, -0.0778, -0.0954,\n",
      "        -0.0058,  0.0982], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.0459,  0.0285,  0.0899, -0.2081,  0.1915, -0.0053, -0.0852, -0.0492,\n",
      "        -0.0394,  0.0515], grad_fn=<AddBackward0>)\n",
      "0.03770795250311494\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input1 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "\n",
    "    input2 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "\n",
    "    input3 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "\n",
    "    losses.append(F.l1_loss(trained_reasoner.and_nn(im(input1, trained_reasoner.and_nn(im(input2, input3)))), trained_reasoner.and_nn(im(trained_reasoner.and_nn(im(input1, input2)), input3))).item())\n",
    "\n",
    "print(trained_reasoner.and_nn(im(input1, trained_reasoner.and_nn(im(input2, input3)))))\n",
    "print(trained_reasoner.and_nn(im(trained_reasoner.and_nn(im(input1, input2)), input3)))\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8878736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0574,  0.0155,  0.0813, -0.1991,  0.1782,  0.0296, -0.0436,  0.0211,\n",
      "        -0.0320,  0.0349], grad_fn=<AddBackward0>)\n",
      "tensor([ 0.1004, -0.0202,  0.0521, -0.2140,  0.1707, -0.0263, -0.0697,  0.0596,\n",
      "        -0.1071,  0.0224], grad_fn=<AddBackward0>)\n",
      "0.029833172308281065\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input1 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "    input2 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "\n",
    "    losses.append( F.l1_loss(trained_reasoner.and_nn(im(input1, input2)), trained_reasoner.and_nn(im(input2, input1))).item())\n",
    "\n",
    "print(trained_reasoner.and_nn(im(input1, input2)))\n",
    "print(trained_reasoner.and_nn(im(input2, input1)))\n",
    "\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e840d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1733,  0.2138, -0.0319, -0.2493,  0.1992,  0.0884,  0.0452,  0.0611,\n",
      "        -0.2770,  0.0685], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0836,  0.1108,  0.0115, -0.2417,  0.0640,  0.0104,  0.0819,  0.1758,\n",
      "        -0.1955, -0.0690], grad_fn=<AddBackward0>)\n",
      "0.1997889805585146\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input1 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "    losses.append(F.l1_loss(input1, trained_reasoner.and_nn(im(input1, trained_reasoner.top_concept[0]))).item())\n",
    "\n",
    "print(input1)\n",
    "print(trained_reasoner.and_nn(im(input1, trained_reasoner.top_concept[0])))\n",
    "\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58620be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999014347791672\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input1 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "    losses.append( T.sigmoid(trained_reasoner.sub_nn(im(input1, trained_reasoner.top_concept[0]))).item())\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43b1bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for _ in range(20):\n",
    "    encoder = trained_test_encoders['trained reasoner'][int(np.round(random.random() * (len(trained_test_encoders['trained reasoner'] ) - 1) , 0))]\n",
    "    input1 = encoder.concepts[int(np.round(random. random() * encoder.n_concepts, 0) - 1)]\n",
    "    losses.append(T.sigmoid(trained_reasoner.sub_nn(im(trained_reasoner.bot_concept[0], trained_reasoner.bot_concept[0]))).item())\n",
    "print(np.mean(losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
